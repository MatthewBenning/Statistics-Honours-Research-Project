{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "multistep_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8UNojMkGclReGkzdHMpe4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewBenning/Statistics-Honours-Research-Project/blob/main/multistep_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_MDT0DBVu6e",
        "outputId": "06fc91f9-e84c-46a2-efd7-c5dde3a5de82"
      },
      "source": [
        "# LSTM for Multistep Forecasting \n",
        "# Author: Matthew Benning\n",
        "# Adapted from Eligijus Bujokas weather forecast framework with multivariate input\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import random \n",
        "import tensorflow as ts\n",
        "import statsmodels\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.stattools import coint, adfuller\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "# Neccessary imports for LSTM, Keras package will be used\n",
        "from tensorflow import keras\n",
        "from keras.models import Input, Model, Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Concatenate, SimpleRNN, Masking, Flatten\n",
        "from keras import losses\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.initializers import RandomNormal\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "images_dir = '/content/gdrive/MyDrive/Statistics Honours Research Project'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stRI-kFtXyGR"
      },
      "source": [
        "\n",
        "# First read in the JSE data set and convert it to a timeseries object\n",
        "data = pd.read_excel('/content/gdrive/MyDrive/Statistics Honours Research Project/spread_series.xlsx',index_col=0)\n",
        "data = data.dropna()\n",
        "\n",
        "# Now we need to train each model individually, so we get series isolated\n",
        "data_1 = data.iloc[:,0]\n",
        "data_2 = data.iloc[:,1]\n",
        "data_3 = data.iloc[:,2]\n",
        "data_4 = data.iloc[:,3]\n",
        "data_5 = data.iloc[:,4]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzce7ZD6iBlD"
      },
      "source": [
        "# Asset Pair 1 LSTM \n",
        "# Run everything\n",
        "#############################################################\n",
        "# We can adjust these but this is the correct parameter specs for final model\n",
        "\n",
        "# Number of look back days to use = we use last 365 trading days\n",
        "lag = 90\n",
        "# Steps ahead to forecast \n",
        "n_ahead = 7\n",
        "# S30% of the data is in the testing period\n",
        "test_share = 0.2\n",
        "# Epochs for training\n",
        "epochs = 50\n",
        "# Batch size \n",
        "batch_size = 500\n",
        "# Learning rate\n",
        "lr = 0.0001\n",
        "# Number of neurons in LSTM layer\n",
        "n_layer = 50\n",
        "\n",
        "# We use the past x days as input\n",
        "# Create the correct sequential data for LSTM X, Y series\n",
        "def form_XY(ts: np.array, lag=1, n_ahead=1, target_index=0) -> tuple:\n",
        "   \n",
        "    # Extracting the number of features that are passed from the array \n",
        "    n_features = 1\n",
        "\n",
        "    # Creating placeholder lists\n",
        "    X, Y = [], []\n",
        "\n",
        "    if len(ts) - lag <= 0:\n",
        "        X.append(ts)\n",
        "    else:\n",
        "        for i in range(len(ts) - lag - n_ahead):\n",
        "            Y.append(ts[(i + lag):(i + lag + n_ahead)])\n",
        "            X.append(ts[i:(i + lag)])\n",
        "\n",
        "    X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "    # Reshaping the X array to an RNN input shape \n",
        "    X = np.reshape(X, (X.shape[0], lag, n_features))\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# Run for our spread data\n",
        "X,Y = form_XY(data_1,lag=365,n_ahead=1,target_index=0)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "############################################################\n",
        "\n",
        "# Set up the model class \n",
        "# We want an iteractive model training process so we include the \n",
        "# TrainCallback function which prevents over fitting once a certain mse reached\n",
        "\n",
        "class LSTM_spread_forecast():\n",
        "    \n",
        "    # Initialize our model class members\n",
        "    # Have kept the typescript set up as I just learnt it and its nice! MB :D\n",
        "    def __init__(\n",
        "        self, \n",
        "        X, \n",
        "        Y, \n",
        "        n_outputs,\n",
        "        n_lag,\n",
        "        n_ft,\n",
        "        n_layer,\n",
        "        batch,\n",
        "        epochs, \n",
        "        lr,\n",
        "        Xval=None,\n",
        "        Yval=None,\n",
        "        mask_value=-999.0,\n",
        "        min_delta=0.001,\n",
        "        patience=5\n",
        "    ):\n",
        "        lstm_input = Input(shape=(n_lag, 1))\n",
        "\n",
        "        \n",
        "        lstm_layer = LSTM(n_layer, activation='relu')(lstm_input)\n",
        "\n",
        "        x = Dense(n_outputs)(lstm_layer)\n",
        "        \n",
        "        self.model = Model(inputs=lstm_input, outputs=x)\n",
        "        self.batch = batch \n",
        "        self.epochs = epochs\n",
        "        self.n_layer=n_layer\n",
        "        self.lr = lr \n",
        "        self.Xval = Xval\n",
        "        self.Yval = Yval\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.mask_value = mask_value\n",
        "        self.min_delta = min_delta\n",
        "        self.patience = patience\n",
        "\n",
        "    def trainCallback(self):\n",
        "        return EarlyStopping(monitor='loss', patience=self.patience, min_delta=self.min_delta)\n",
        "\n",
        "    def train(self):\n",
        "        # Getting the untrained model \n",
        "        empty_model = self.model\n",
        "        \n",
        "        # Init the optimizer\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=self.lr)\n",
        "\n",
        "        # Compile the model\n",
        "        empty_model.compile(loss=losses.MeanAbsoluteError(), optimizer=optimizer)\n",
        "\n",
        "        if (self.Xval is not None) & (self.Yval is not None):\n",
        "            history = empty_model.fit(\n",
        "                self.X, \n",
        "                self.Y, \n",
        "                epochs=self.epochs, \n",
        "                batch_size=self.batch, \n",
        "                validation_data=(self.Xval, self.Yval), \n",
        "                shuffle=False,\n",
        "                callbacks=[self.trainCallback()]\n",
        "            )\n",
        "        else:\n",
        "            history = empty_model.fit(\n",
        "                self.X, \n",
        "                self.Y, \n",
        "                epochs=self.epochs, \n",
        "                batch_size=self.batch,\n",
        "                shuffle=False,\n",
        "                callbacks=[self.trainCallback()]\n",
        "            )\n",
        "        \n",
        "        # Saving to original model attribute in the class\n",
        "        self.model = empty_model\n",
        "        \n",
        "        # Returning the training history\n",
        "        return history\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "############################################################################\n",
        "# Now that model class is initiated we need to scale\n",
        "# Important that we scale the train and test seperately as to not introduce \n",
        "# any look back bias\n",
        "\n",
        "\n",
        "nrows = data_1.shape[0]\n",
        "# Spliting into train and test sets\n",
        "train = data_1[0:int(nrows * (1 -test_share))]\n",
        "test = data_1[int(nrows * (1 -test_share)):]\n",
        "# Scaling the data \n",
        "train_mean = train.mean()\n",
        "train_std = train.std()\n",
        "train = (train - train_mean) / train_std\n",
        "test = (test -train_mean) / train_std\n",
        "# Creating the final scaled frame \n",
        "ts_s = pd.concat([train, test])\n",
        "# Creating the X and Y for training\n",
        "X, Y = form_XY(ts_s.values, lag=lag, n_ahead=n_ahead)\n",
        "n_ft = 1\n",
        "\n",
        "########################################################################\n",
        "# Scaling done, now we can split the data into the respective subsets\n",
        "\n",
        "# Train and test splits\n",
        "Xtrain, Ytrain = X[0:int(X.shape[0] * (1 - test_share-0.10))], Y[0:int(X.shape[0] * (1 -test_share-0.10))]\n",
        "Xval, Yval = X[int(X.shape[0] * (1-test_share)):], Y[int(X.shape[0] * (1 -test_share)):]\n",
        "\n",
        "\n",
        "# Verify the final shapes, making sure correct set up for LSTM\n",
        "print(Xtrain.shape)\n",
        "print(Ytrain.shape)\n",
        "print(Xval.shape)\n",
        "print(Yval.shape)\n",
        "# Looks good to go!\n",
        "\n",
        "#####################################################################\n",
        "# Set up model class for the pair spread\n",
        "\n",
        "model_pair1 = LSTM_spread_forecast(\n",
        " X=Xtrain,\n",
        " Y=Ytrain,\n",
        " n_outputs=n_ahead,\n",
        " n_lag=lag,\n",
        " n_ft=n_ft,\n",
        " n_layer=n_layer,\n",
        " batch=batch_size,\n",
        " epochs=epochs, \n",
        " lr=lr,\n",
        " Xval=Xval,\n",
        " Yval=Yval,\n",
        ")\n",
        "# Check the model summary before running\n",
        "model_pair1.model.summary()\n",
        "# Training of the model \n",
        "history = model_pair1.train()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfFHc1owUvI0",
        "outputId": "49b02772-be82-4700-e684-d41e98e2ae64"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.callbacks.History object at 0x7f238604fc10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV9D1bSrSYuP",
        "outputId": "9350e246-9cbd-44a8-87a7-c3998cbb8343"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "for i in range(10):\n",
        "  for j in range (12):\n",
        "\n",
        "    # Number of look back days to use = we use last 365 trading days\n",
        "    lag = 10*(1+i)\n",
        "    # Steps ahead to forecast \n",
        "    n_ahead = 7\n",
        "    # S30% of the data is in the testing period\n",
        "    test_share = 0.2\n",
        "    # Epochs for training\n",
        "    epochs = 100\n",
        "    # Batch size \n",
        "    batch_size = 500\n",
        "    # Learning rate\n",
        "    lr = 0.0001\n",
        "    # Number of neurons in LSTM layer\n",
        "    n_layer = 5*(1+j)\n",
        "\n",
        "    # We use the past x days as input\n",
        "    # Create the correct sequential data for LSTM X, Y series\n",
        "    def form_XY(ts: np.array, lag=1, n_ahead=1, target_index=0) -> tuple:\n",
        "      \n",
        "        # Extracting the number of features that are passed from the array \n",
        "        n_features = 1\n",
        "\n",
        "        # Creating placeholder lists\n",
        "        X, Y = [], []\n",
        "\n",
        "        if len(ts) - lag <= 0:\n",
        "            X.append(ts)\n",
        "        else:\n",
        "            for i in range(len(ts) - lag - n_ahead):\n",
        "                Y.append(ts[(i + lag):(i + lag + n_ahead)])\n",
        "                X.append(ts[i:(i + lag)])\n",
        "\n",
        "        X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "        # Reshaping the X array to an RNN input shape \n",
        "        X = np.reshape(X, (X.shape[0], lag, n_features))\n",
        "\n",
        "        return X, Y\n",
        "\n",
        "    # Run for our spread data\n",
        "    X,Y = form_XY(data_1,lag=365,n_ahead=1,target_index=0)\n",
        "\n",
        "    print(X.shape)\n",
        "    print(Y.shape)\n",
        "\n",
        "    ############################################################\n",
        "\n",
        "    # Set up the model class \n",
        "    # We want an iteractive model training process so we include the \n",
        "    # TrainCallback function which prevents over fitting once a certain mse reached\n",
        "\n",
        "    class LSTM_spread_forecast():\n",
        "        \n",
        "        # Initialize our model class members\n",
        "        # Have kept the typescript set up as I just learnt it and its nice! MB :D\n",
        "        def __init__(\n",
        "            self, \n",
        "            X, \n",
        "            Y, \n",
        "            n_outputs,\n",
        "            n_lag,\n",
        "            n_ft,\n",
        "            n_layer,\n",
        "            batch,\n",
        "            epochs, \n",
        "            lr,\n",
        "            Xval=None,\n",
        "            Yval=None,\n",
        "            mask_value=-999.0,\n",
        "            min_delta=0.001,\n",
        "            patience=5\n",
        "        ):\n",
        "            lstm_input = Input(shape=(n_lag, 1))\n",
        "\n",
        "            \n",
        "            lstm_layer = LSTM(n_layer, activation='relu')(lstm_input)\n",
        "\n",
        "            x = Dense(n_outputs)(lstm_layer)\n",
        "            \n",
        "            self.model = Model(inputs=lstm_input, outputs=x)\n",
        "            self.batch = batch \n",
        "            self.epochs = epochs\n",
        "            self.n_layer=n_layer\n",
        "            self.lr = lr \n",
        "            self.Xval = Xval\n",
        "            self.Yval = Yval\n",
        "            self.X = X\n",
        "            self.Y = Y\n",
        "            self.mask_value = mask_value\n",
        "            self.min_delta = min_delta\n",
        "            self.patience = patience\n",
        "\n",
        "        def trainCallback(self):\n",
        "            return EarlyStopping(monitor='loss', patience=self.patience, min_delta=self.min_delta)\n",
        "\n",
        "        def train(self):\n",
        "            # Getting the untrained model \n",
        "            empty_model = self.model\n",
        "            \n",
        "            # Init the optimizer\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=self.lr)\n",
        "\n",
        "            # Compile the model\n",
        "            empty_model.compile(loss=losses.MeanAbsoluteError(), optimizer=optimizer)\n",
        "\n",
        "            if (self.Xval is not None) & (self.Yval is not None):\n",
        "                history = empty_model.fit(\n",
        "                    self.X, \n",
        "                    self.Y, \n",
        "                    epochs=self.epochs, \n",
        "                    batch_size=self.batch, \n",
        "                    validation_data=(self.Xval, self.Yval), \n",
        "                    shuffle=False,\n",
        "                    callbacks=[self.trainCallback()]\n",
        "                )\n",
        "            else:\n",
        "                history = empty_model.fit(\n",
        "                    self.X, \n",
        "                    self.Y, \n",
        "                    epochs=self.epochs, \n",
        "                    batch_size=self.batch,\n",
        "                    shuffle=False,\n",
        "                    callbacks=[self.trainCallback()]\n",
        "                )\n",
        "            \n",
        "            # Saving to original model attribute in the class\n",
        "            self.model = empty_model\n",
        "            \n",
        "            # Returning the training history\n",
        "            return history\n",
        "        \n",
        "        def predict(self, X):\n",
        "            return self.model.predict(X)\n",
        "\n",
        "    ############################################################################\n",
        "    # Now that model class is initiated we need to scale\n",
        "    # Important that we scale the train and test seperately as to not introduce \n",
        "    # any look back bias\n",
        "\n",
        "\n",
        "    nrows = data_1.shape[0]\n",
        "    # Spliting into train and test sets\n",
        "    train = data_1[0:int(nrows * (1 -test_share))]\n",
        "    test = data_1[int(nrows * (1 -test_share)):]\n",
        "    # Scaling the data \n",
        "    train_mean = train.mean()\n",
        "    train_std = train.std()\n",
        "    train = (train - train_mean) / train_std\n",
        "    test = (test -train_mean) / train_std\n",
        "    # Creating the final scaled frame \n",
        "    ts_s = pd.concat([train, test])\n",
        "    # Creating the X and Y for training\n",
        "    X, Y = form_XY(ts_s.values, lag=lag, n_ahead=n_ahead)\n",
        "    n_ft = 1\n",
        "\n",
        "    ########################################################################\n",
        "    # Scaling done, now we can split the data into the respective subsets\n",
        "\n",
        "    # Train and test splits\n",
        "    Xtrain, Ytrain = X[0:int(X.shape[0] * (1 - test_share-0.10))], Y[0:int(X.shape[0] * (1 -test_share-0.10))]\n",
        "    #Xval, Yval = X[int(X.shape[0] * (1-test_share)):], Y[int(X.shape[0] * (1 -test_share)):]\n",
        "    Xval, Yval = X[int(X.shape[0] * (1-test_share-0.1)):int(X.shape[0] * (1-test_share))], Y[int(X.shape[0] * (1 -test_share-0.1)):int(X.shape[0] * (1-test_share))]\n",
        "    Xtest, Ytest = X[int(X.shape[0] * (1-test_share)):], Y[int(X.shape[0] * (1 -test_share)):]\n",
        "\n",
        "\n",
        "    # Verify the final shapes, making sure correct set up for LSTM\n",
        "    #print(Xtrain.shape)\n",
        "    #print(Ytrain.shape)\n",
        "    #print(Xval.shape)\n",
        "    #print(Yval.shape)\n",
        "    # Looks good to go!\n",
        "\n",
        "    #####################################################################\n",
        "    # Set up model class for the pair spread\n",
        "\n",
        "    model_pair1 = LSTM_spread_forecast(\n",
        "    X=Xtrain,\n",
        "    Y=Ytrain,\n",
        "    n_outputs=n_ahead,\n",
        "    n_lag=lag,\n",
        "    n_ft=n_ft,\n",
        "    n_layer=n_layer,\n",
        "    batch=batch_size,\n",
        "    epochs=epochs, \n",
        "    lr=lr,\n",
        "    Xval=Xval,\n",
        "    Yval=Yval,\n",
        "    )\n",
        "    # Check the model summary before running\n",
        "    model_pair1.model.summary()\n",
        "    # Training of the model \n",
        "    history = model_pair1.train()\n",
        "    cp = ModelCheckpoint('model_pair1', save_best_only = False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 218ms/step - loss: 0.8582 - val_loss: 0.7873\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.8568 - val_loss: 0.7861\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.8555 - val_loss: 0.7849\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.8541 - val_loss: 0.7837\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.8528 - val_loss: 0.7825\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.8514 - val_loss: 0.7813\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.8501 - val_loss: 0.7800\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.8487 - val_loss: 0.7788\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.8473 - val_loss: 0.7775\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8459 - val_loss: 0.7763\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8445 - val_loss: 0.7749\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.8431 - val_loss: 0.7736\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8417 - val_loss: 0.7723\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.8402 - val_loss: 0.7709\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.8387 - val_loss: 0.7696\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8372 - val_loss: 0.7682\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.8356 - val_loss: 0.7667\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.8340 - val_loss: 0.7653\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.8323 - val_loss: 0.7638\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8306 - val_loss: 0.7623\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.8289 - val_loss: 0.7608\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.8271 - val_loss: 0.7593\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.8253 - val_loss: 0.7577\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.8235 - val_loss: 0.7562\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.8217 - val_loss: 0.7546\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.8199 - val_loss: 0.7530\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8180 - val_loss: 0.7514\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8161 - val_loss: 0.7498\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.8142 - val_loss: 0.7482\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8122 - val_loss: 0.7465\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.8102 - val_loss: 0.7448\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.8081 - val_loss: 0.7431\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.8061 - val_loss: 0.7414\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8039 - val_loss: 0.7396\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.8017 - val_loss: 0.7378\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.7995 - val_loss: 0.7360\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7972 - val_loss: 0.7342\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7948 - val_loss: 0.7323\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7924 - val_loss: 0.7304\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7900 - val_loss: 0.7285\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.7875 - val_loss: 0.7265\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7850 - val_loss: 0.7245\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7823 - val_loss: 0.7224\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.7796 - val_loss: 0.7202\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.7767 - val_loss: 0.7180\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7735 - val_loss: 0.7157\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7701 - val_loss: 0.7131\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7664 - val_loss: 0.7105\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7623 - val_loss: 0.7076\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7579 - val_loss: 0.7047\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7529 - val_loss: 0.7016\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7472 - val_loss: 0.6983\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.7405 - val_loss: 0.6947\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.7324 - val_loss: 0.6910\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7222 - val_loss: 0.6870\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.7113 - val_loss: 0.6828\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7015 - val_loss: 0.6786\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7004 - val_loss: 0.6750\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6936 - val_loss: 0.6730\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6893 - val_loss: 0.6713\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.6874 - val_loss: 0.6691\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6848 - val_loss: 0.6665\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6812 - val_loss: 0.6635\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.6773 - val_loss: 0.6603\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.6735 - val_loss: 0.6572\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.6698 - val_loss: 0.6541\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6660 - val_loss: 0.6510\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6622 - val_loss: 0.6479\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6584 - val_loss: 0.6445\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6544 - val_loss: 0.6409\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6500 - val_loss: 0.6370\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.6453 - val_loss: 0.6330\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.6404 - val_loss: 0.6288\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.6351 - val_loss: 0.6243\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.6294 - val_loss: 0.6196\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6232 - val_loss: 0.6144\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6163 - val_loss: 0.6087\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.6083 - val_loss: 0.6028\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.5990 - val_loss: 0.5978\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.5875 - val_loss: 0.5953\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.5732 - val_loss: 0.6026\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.5559 - val_loss: 0.6512\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.5442 - val_loss: 0.8282\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5519 - val_loss: 0.8253\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.5385 - val_loss: 0.6945\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5357 - val_loss: 0.6528\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.5344 - val_loss: 0.6455\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.5313 - val_loss: 0.6553\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5275 - val_loss: 0.6762\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.5245 - val_loss: 0.6977\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5221 - val_loss: 0.7036\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5193 - val_loss: 0.6911\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.5162 - val_loss: 0.6742\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.5134 - val_loss: 0.6628\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.5107 - val_loss: 0.6583\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.5079 - val_loss: 0.6582\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.5050 - val_loss: 0.6592\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5022 - val_loss: 0.6584\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.4993 - val_loss: 0.6544\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.4965 - val_loss: 0.6488\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_59 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_58 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 233ms/step - loss: 0.8317 - val_loss: 0.7669\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.8303 - val_loss: 0.7657\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.8289 - val_loss: 0.7645\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.8274 - val_loss: 0.7632\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.8260 - val_loss: 0.7620\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.8246 - val_loss: 0.7608\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.8231 - val_loss: 0.7595\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.8216 - val_loss: 0.7583\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.8201 - val_loss: 0.7570\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.8186 - val_loss: 0.7557\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.8171 - val_loss: 0.7545\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.8155 - val_loss: 0.7532\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.8140 - val_loss: 0.7519\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.8124 - val_loss: 0.7506\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.8108 - val_loss: 0.7493\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.8092 - val_loss: 0.7479\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8075 - val_loss: 0.7466\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8059 - val_loss: 0.7452\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.8042 - val_loss: 0.7439\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.8025 - val_loss: 0.7425\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.8007 - val_loss: 0.7411\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.7989 - val_loss: 0.7397\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7971 - val_loss: 0.7382\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7953 - val_loss: 0.7368\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.7934 - val_loss: 0.7353\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.7915 - val_loss: 0.7338\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7895 - val_loss: 0.7323\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.7875 - val_loss: 0.7308\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.7854 - val_loss: 0.7292\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7833 - val_loss: 0.7277\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7811 - val_loss: 0.7261\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7789 - val_loss: 0.7244\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7765 - val_loss: 0.7228\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.7742 - val_loss: 0.7211\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7717 - val_loss: 0.7193\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7691 - val_loss: 0.7176\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7664 - val_loss: 0.7158\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.7636 - val_loss: 0.7140\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.7607 - val_loss: 0.7121\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.7577 - val_loss: 0.7102\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7544 - val_loss: 0.7082\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7510 - val_loss: 0.7062\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7474 - val_loss: 0.7041\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7435 - val_loss: 0.7020\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.7392 - val_loss: 0.6999\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7344 - val_loss: 0.6977\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7290 - val_loss: 0.6954\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7225 - val_loss: 0.6930\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7145 - val_loss: 0.6906\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7049 - val_loss: 0.6881\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6947 - val_loss: 0.6855\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.6991 - val_loss: 0.6834\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6885 - val_loss: 0.6823\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6865 - val_loss: 0.6811\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.6855 - val_loss: 0.6795\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.6822 - val_loss: 0.6777\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6780 - val_loss: 0.6758\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.6752 - val_loss: 0.6741\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.6723 - val_loss: 0.6726\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6689 - val_loss: 0.6712\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6664 - val_loss: 0.6699\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6634 - val_loss: 0.6685\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.6602 - val_loss: 0.6672\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.6570 - val_loss: 0.6661\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6538 - val_loss: 0.6652\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6507 - val_loss: 0.6643\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6476 - val_loss: 0.6636\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6444 - val_loss: 0.6631\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6413 - val_loss: 0.6631\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6382 - val_loss: 0.6639\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.6354 - val_loss: 0.6659\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6326 - val_loss: 0.6689\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6300 - val_loss: 0.6726\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.6276 - val_loss: 0.6757\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6254 - val_loss: 0.6772\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6231 - val_loss: 0.6766\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6207 - val_loss: 0.6746\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.6183 - val_loss: 0.6723\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.6160 - val_loss: 0.6700\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6137 - val_loss: 0.6681\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6114 - val_loss: 0.6667\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6091 - val_loss: 0.6658\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.6068 - val_loss: 0.6651\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6045 - val_loss: 0.6645\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.6022 - val_loss: 0.6640\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5999 - val_loss: 0.6631\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.5976 - val_loss: 0.6621\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5953 - val_loss: 0.6611\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.5930 - val_loss: 0.6601\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5906 - val_loss: 0.6592\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5882 - val_loss: 0.6588\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.5858 - val_loss: 0.6584\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.5834 - val_loss: 0.6578\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.5810 - val_loss: 0.6566\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.5786 - val_loss: 0.6550\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.5762 - val_loss: 0.6534\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.5739 - val_loss: 0.6520\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5716 - val_loss: 0.6508\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5693 - val_loss: 0.6497\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5670 - val_loss: 0.6484\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_60 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_59 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 252ms/step - loss: 0.8206 - val_loss: 0.7551\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.8193 - val_loss: 0.7540\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.8180 - val_loss: 0.7529\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.8167 - val_loss: 0.7518\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8154 - val_loss: 0.7506\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.8140 - val_loss: 0.7495\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8127 - val_loss: 0.7484\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.8113 - val_loss: 0.7472\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.8100 - val_loss: 0.7461\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.8086 - val_loss: 0.7449\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.8072 - val_loss: 0.7437\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.8058 - val_loss: 0.7425\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8044 - val_loss: 0.7413\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8030 - val_loss: 0.7401\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.8015 - val_loss: 0.7389\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.8000 - val_loss: 0.7376\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7985 - val_loss: 0.7363\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7969 - val_loss: 0.7350\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7953 - val_loss: 0.7337\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7936 - val_loss: 0.7323\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7918 - val_loss: 0.7309\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7901 - val_loss: 0.7295\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.7883 - val_loss: 0.7280\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7864 - val_loss: 0.7265\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7846 - val_loss: 0.7250\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7826 - val_loss: 0.7235\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.7807 - val_loss: 0.7219\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7786 - val_loss: 0.7203\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7766 - val_loss: 0.7186\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.7744 - val_loss: 0.7170\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.7722 - val_loss: 0.7152\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7700 - val_loss: 0.7135\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7676 - val_loss: 0.7117\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.7652 - val_loss: 0.7098\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7627 - val_loss: 0.7079\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7601 - val_loss: 0.7060\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.7573 - val_loss: 0.7040\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7545 - val_loss: 0.7019\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.7515 - val_loss: 0.6998\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7484 - val_loss: 0.6976\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7450 - val_loss: 0.6953\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7415 - val_loss: 0.6930\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.7378 - val_loss: 0.6906\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7337 - val_loss: 0.6880\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7293 - val_loss: 0.6853\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7245 - val_loss: 0.6826\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7191 - val_loss: 0.6796\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7131 - val_loss: 0.6766\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7062 - val_loss: 0.6734\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.6983 - val_loss: 0.6700\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.6897 - val_loss: 0.6665\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6816 - val_loss: 0.6628\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.6754 - val_loss: 0.6592\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.6709 - val_loss: 0.6559\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6674 - val_loss: 0.6530\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6637 - val_loss: 0.6506\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.6597 - val_loss: 0.6486\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.6563 - val_loss: 0.6466\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6533 - val_loss: 0.6444\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6501 - val_loss: 0.6419\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6466 - val_loss: 0.6393\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.6431 - val_loss: 0.6367\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.6395 - val_loss: 0.6340\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.6359 - val_loss: 0.6313\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.6322 - val_loss: 0.6287\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.6285 - val_loss: 0.6260\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6248 - val_loss: 0.6233\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.6210 - val_loss: 0.6205\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6170 - val_loss: 0.6176\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6128 - val_loss: 0.6145\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.6084 - val_loss: 0.6113\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6037 - val_loss: 0.6079\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5993 - val_loss: 0.6046\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5951 - val_loss: 0.6013\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.5911 - val_loss: 0.5981\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5872 - val_loss: 0.5945\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.5830 - val_loss: 0.5906\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.5784 - val_loss: 0.5862\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5734 - val_loss: 0.5815\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.5679 - val_loss: 0.5766\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.5620 - val_loss: 0.5713\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.5555 - val_loss: 0.5658\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.5482 - val_loss: 0.5603\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5399 - val_loss: 0.5564\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.5299 - val_loss: 0.5558\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5176 - val_loss: 0.5692\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.5032 - val_loss: 0.6246\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.4898 - val_loss: 0.7851\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.4900 - val_loss: 0.9054\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.4857 - val_loss: 0.8109\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.4791 - val_loss: 0.7194\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.4762 - val_loss: 0.6793\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.4737 - val_loss: 0.6723\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.4703 - val_loss: 0.6845\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.4665 - val_loss: 0.7055\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.4631 - val_loss: 0.7193\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.4598 - val_loss: 0.7159\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.4562 - val_loss: 0.7006\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.4526 - val_loss: 0.6842\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.4491 - val_loss: 0.6730\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_61 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_60 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 225ms/step - loss: 0.8523 - val_loss: 0.7809\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.8505 - val_loss: 0.7795\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8487 - val_loss: 0.7780\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8468 - val_loss: 0.7766\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8450 - val_loss: 0.7752\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8431 - val_loss: 0.7737\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8413 - val_loss: 0.7722\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8394 - val_loss: 0.7707\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.8375 - val_loss: 0.7692\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.8356 - val_loss: 0.7677\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.8336 - val_loss: 0.7661\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.8317 - val_loss: 0.7645\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.8297 - val_loss: 0.7629\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.8277 - val_loss: 0.7613\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8257 - val_loss: 0.7597\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.8236 - val_loss: 0.7580\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.8216 - val_loss: 0.7564\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.8195 - val_loss: 0.7547\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8174 - val_loss: 0.7530\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.8153 - val_loss: 0.7513\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.8132 - val_loss: 0.7496\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.8110 - val_loss: 0.7478\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.8088 - val_loss: 0.7460\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.8065 - val_loss: 0.7442\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8042 - val_loss: 0.7424\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8019 - val_loss: 0.7406\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7995 - val_loss: 0.7387\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7971 - val_loss: 0.7368\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7946 - val_loss: 0.7349\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7920 - val_loss: 0.7330\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7893 - val_loss: 0.7310\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7866 - val_loss: 0.7289\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7837 - val_loss: 0.7268\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7808 - val_loss: 0.7247\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7777 - val_loss: 0.7225\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7744 - val_loss: 0.7203\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7710 - val_loss: 0.7180\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.7674 - val_loss: 0.7156\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7636 - val_loss: 0.7132\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.7595 - val_loss: 0.7107\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7550 - val_loss: 0.7081\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7501 - val_loss: 0.7054\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.7447 - val_loss: 0.7026\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7388 - val_loss: 0.6997\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7326 - val_loss: 0.6967\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.7264 - val_loss: 0.6936\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.7204 - val_loss: 0.6905\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7152 - val_loss: 0.6875\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7111 - val_loss: 0.6848\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7073 - val_loss: 0.6824\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7034 - val_loss: 0.6802\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6993 - val_loss: 0.6783\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6952 - val_loss: 0.6763\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6911 - val_loss: 0.6743\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6867 - val_loss: 0.6721\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.6819 - val_loss: 0.6698\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6767 - val_loss: 0.6674\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.6714 - val_loss: 0.6649\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6663 - val_loss: 0.6627\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6615 - val_loss: 0.6607\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6572 - val_loss: 0.6589\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6536 - val_loss: 0.6572\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 192ms/step - loss: 0.6505 - val_loss: 0.6554\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6477 - val_loss: 0.6535\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6450 - val_loss: 0.6514\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6421 - val_loss: 0.6493\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6393 - val_loss: 0.6470\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6363 - val_loss: 0.6447\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.6332 - val_loss: 0.6423\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6302 - val_loss: 0.6399\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6271 - val_loss: 0.6374\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6239 - val_loss: 0.6349\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6207 - val_loss: 0.6324\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.6176 - val_loss: 0.6299\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6144 - val_loss: 0.6274\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6112 - val_loss: 0.6247\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6079 - val_loss: 0.6221\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.6045 - val_loss: 0.6195\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6012 - val_loss: 0.6169\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.5978 - val_loss: 0.6142\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5943 - val_loss: 0.6114\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.5906 - val_loss: 0.6086\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5870 - val_loss: 0.6058\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.5833 - val_loss: 0.6030\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.5795 - val_loss: 0.6001\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5756 - val_loss: 0.5971\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5716 - val_loss: 0.5940\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5674 - val_loss: 0.5908\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5632 - val_loss: 0.5876\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5588 - val_loss: 0.5841\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.5542 - val_loss: 0.5806\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5495 - val_loss: 0.5770\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.5446 - val_loss: 0.5734\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5394 - val_loss: 0.5697\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.5340 - val_loss: 0.5659\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.5283 - val_loss: 0.5621\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.5223 - val_loss: 0.5580\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5160 - val_loss: 0.5540\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5091 - val_loss: 0.5501\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.5018 - val_loss: 0.5468\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_62 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_61 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 232ms/step - loss: 0.8325 - val_loss: 0.7674\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.8309 - val_loss: 0.7661\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8293 - val_loss: 0.7647\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.8277 - val_loss: 0.7634\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8262 - val_loss: 0.7621\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.8246 - val_loss: 0.7607\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8230 - val_loss: 0.7594\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.8214 - val_loss: 0.7580\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.8199 - val_loss: 0.7567\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8183 - val_loss: 0.7554\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.8167 - val_loss: 0.7540\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8151 - val_loss: 0.7527\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8135 - val_loss: 0.7513\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8119 - val_loss: 0.7500\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8103 - val_loss: 0.7486\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.8086 - val_loss: 0.7473\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8070 - val_loss: 0.7459\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8053 - val_loss: 0.7445\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8036 - val_loss: 0.7432\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8018 - val_loss: 0.7418\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.8001 - val_loss: 0.7404\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7983 - val_loss: 0.7390\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7965 - val_loss: 0.7376\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7946 - val_loss: 0.7362\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7927 - val_loss: 0.7347\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7908 - val_loss: 0.7333\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7888 - val_loss: 0.7318\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7868 - val_loss: 0.7303\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7847 - val_loss: 0.7287\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7825 - val_loss: 0.7272\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.7802 - val_loss: 0.7255\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7779 - val_loss: 0.7239\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7754 - val_loss: 0.7221\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7728 - val_loss: 0.7204\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7700 - val_loss: 0.7186\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.7670 - val_loss: 0.7167\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7638 - val_loss: 0.7147\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7602 - val_loss: 0.7127\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.7563 - val_loss: 0.7106\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7518 - val_loss: 0.7084\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7467 - val_loss: 0.7061\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7408 - val_loss: 0.7038\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7347 - val_loss: 0.7014\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.7296 - val_loss: 0.6990\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7258 - val_loss: 0.6968\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.7224 - val_loss: 0.6948\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7188 - val_loss: 0.6931\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.7150 - val_loss: 0.6915\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.7114 - val_loss: 0.6900\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7078 - val_loss: 0.6883\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.7040 - val_loss: 0.6866\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6998 - val_loss: 0.6848\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6952 - val_loss: 0.6828\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6901 - val_loss: 0.6809\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6843 - val_loss: 0.6789\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6780 - val_loss: 0.6770\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6726 - val_loss: 0.6756\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6675 - val_loss: 0.6748\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.6643 - val_loss: 0.6736\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.6609 - val_loss: 0.6724\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6575 - val_loss: 0.6715\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.6553 - val_loss: 0.6704\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.6529 - val_loss: 0.6692\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6505 - val_loss: 0.6682\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6487 - val_loss: 0.6671\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6466 - val_loss: 0.6658\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6444 - val_loss: 0.6647\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6424 - val_loss: 0.6636\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6405 - val_loss: 0.6624\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6385 - val_loss: 0.6612\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6365 - val_loss: 0.6600\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.6347 - val_loss: 0.6589\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6329 - val_loss: 0.6577\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6310 - val_loss: 0.6565\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.6293 - val_loss: 0.6553\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6276 - val_loss: 0.6541\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6257 - val_loss: 0.6529\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.6240 - val_loss: 0.6516\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6223 - val_loss: 0.6504\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6205 - val_loss: 0.6491\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6188 - val_loss: 0.6479\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6171 - val_loss: 0.6466\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6154 - val_loss: 0.6452\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.6136 - val_loss: 0.6439\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6119 - val_loss: 0.6426\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6102 - val_loss: 0.6413\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6086 - val_loss: 0.6399\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6069 - val_loss: 0.6384\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.6052 - val_loss: 0.6370\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6035 - val_loss: 0.6355\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6017 - val_loss: 0.6340\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6000 - val_loss: 0.6325\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.5981 - val_loss: 0.6309\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.5963 - val_loss: 0.6294\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.5945 - val_loss: 0.6278\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.5927 - val_loss: 0.6261\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.5908 - val_loss: 0.6244\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.5888 - val_loss: 0.6227\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.5869 - val_loss: 0.6210\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5849 - val_loss: 0.6193\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_63 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_62 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 239ms/step - loss: 0.8439 - val_loss: 0.7761\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.8424 - val_loss: 0.7749\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8410 - val_loss: 0.7737\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8396 - val_loss: 0.7725\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8382 - val_loss: 0.7713\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.8369 - val_loss: 0.7701\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8355 - val_loss: 0.7689\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.8341 - val_loss: 0.7677\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.8327 - val_loss: 0.7665\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8313 - val_loss: 0.7652\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8299 - val_loss: 0.7640\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.8285 - val_loss: 0.7628\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.8271 - val_loss: 0.7615\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.8257 - val_loss: 0.7603\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8242 - val_loss: 0.7590\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.8227 - val_loss: 0.7578\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.8213 - val_loss: 0.7565\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.8198 - val_loss: 0.7552\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.8182 - val_loss: 0.7539\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.8167 - val_loss: 0.7525\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8151 - val_loss: 0.7512\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8135 - val_loss: 0.7498\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8119 - val_loss: 0.7484\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.8102 - val_loss: 0.7470\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8086 - val_loss: 0.7455\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8068 - val_loss: 0.7440\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.8051 - val_loss: 0.7425\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8033 - val_loss: 0.7410\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8015 - val_loss: 0.7394\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7996 - val_loss: 0.7378\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7977 - val_loss: 0.7361\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7957 - val_loss: 0.7344\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7937 - val_loss: 0.7327\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.7917 - val_loss: 0.7309\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7896 - val_loss: 0.7291\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7874 - val_loss: 0.7272\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7852 - val_loss: 0.7253\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.7829 - val_loss: 0.7234\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7805 - val_loss: 0.7213\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7780 - val_loss: 0.7193\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7755 - val_loss: 0.7171\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7729 - val_loss: 0.7149\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7702 - val_loss: 0.7126\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7674 - val_loss: 0.7101\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7644 - val_loss: 0.7076\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7613 - val_loss: 0.7051\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7581 - val_loss: 0.7024\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7547 - val_loss: 0.6996\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7512 - val_loss: 0.6967\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7474 - val_loss: 0.6937\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7434 - val_loss: 0.6908\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7391 - val_loss: 0.6877\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.7345 - val_loss: 0.6845\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7296 - val_loss: 0.6816\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7242 - val_loss: 0.6789\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7183 - val_loss: 0.6771\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7118 - val_loss: 0.6762\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7046 - val_loss: 0.6777\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6967 - val_loss: 0.6840\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6886 - val_loss: 0.6963\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6814 - val_loss: 0.7169\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6770 - val_loss: 0.7341\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6728 - val_loss: 0.7315\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6674 - val_loss: 0.7186\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6619 - val_loss: 0.7069\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6566 - val_loss: 0.6995\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6513 - val_loss: 0.6962\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6455 - val_loss: 0.6957\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.6393 - val_loss: 0.6965\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6325 - val_loss: 0.6972\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6261 - val_loss: 0.6970\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6208 - val_loss: 0.6952\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6167 - val_loss: 0.6918\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6128 - val_loss: 0.6875\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6088 - val_loss: 0.6835\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6049 - val_loss: 0.6804\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6012 - val_loss: 0.6780\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5976 - val_loss: 0.6756\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5940 - val_loss: 0.6728\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.5903 - val_loss: 0.6692\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.5866 - val_loss: 0.6653\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5829 - val_loss: 0.6613\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.5790 - val_loss: 0.6577\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.5752 - val_loss: 0.6545\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.5713 - val_loss: 0.6517\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.5674 - val_loss: 0.6490\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5634 - val_loss: 0.6463\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.5593 - val_loss: 0.6434\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.5550 - val_loss: 0.6402\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.5503 - val_loss: 0.6368\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.5454 - val_loss: 0.6327\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5403 - val_loss: 0.6281\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.5349 - val_loss: 0.6236\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5293 - val_loss: 0.6196\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5233 - val_loss: 0.6161\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.5170 - val_loss: 0.6127\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5102 - val_loss: 0.6089\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5025 - val_loss: 0.6046\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.4951 - val_loss: 0.6004\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.4891 - val_loss: 0.5968\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_64 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_63 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 236ms/step - loss: 0.8302 - val_loss: 0.7673\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.8290 - val_loss: 0.7663\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.8278 - val_loss: 0.7653\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 0.8267 - val_loss: 0.7643\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8255 - val_loss: 0.7633\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.8243 - val_loss: 0.7623\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.8231 - val_loss: 0.7613\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8219 - val_loss: 0.7602\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.8207 - val_loss: 0.7592\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8195 - val_loss: 0.7582\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8182 - val_loss: 0.7571\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8170 - val_loss: 0.7561\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8157 - val_loss: 0.7550\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8144 - val_loss: 0.7540\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8131 - val_loss: 0.7529\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8118 - val_loss: 0.7517\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8104 - val_loss: 0.7506\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8090 - val_loss: 0.7495\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.8076 - val_loss: 0.7483\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8062 - val_loss: 0.7471\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.8048 - val_loss: 0.7459\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8033 - val_loss: 0.7446\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8017 - val_loss: 0.7434\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8002 - val_loss: 0.7421\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.7986 - val_loss: 0.7408\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7970 - val_loss: 0.7395\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7953 - val_loss: 0.7381\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7936 - val_loss: 0.7367\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7919 - val_loss: 0.7353\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7901 - val_loss: 0.7339\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7883 - val_loss: 0.7324\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7865 - val_loss: 0.7309\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7845 - val_loss: 0.7294\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7826 - val_loss: 0.7278\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7805 - val_loss: 0.7262\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7784 - val_loss: 0.7245\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7762 - val_loss: 0.7228\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7739 - val_loss: 0.7211\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7715 - val_loss: 0.7194\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7691 - val_loss: 0.7175\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7664 - val_loss: 0.7157\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7637 - val_loss: 0.7138\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7607 - val_loss: 0.7118\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7575 - val_loss: 0.7097\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7539 - val_loss: 0.7076\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7499 - val_loss: 0.7054\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7455 - val_loss: 0.7031\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7412 - val_loss: 0.7008\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7375 - val_loss: 0.6985\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7351 - val_loss: 0.6962\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7322 - val_loss: 0.6943\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7293 - val_loss: 0.6924\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7268 - val_loss: 0.6904\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7243 - val_loss: 0.6884\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7216 - val_loss: 0.6862\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7187 - val_loss: 0.6839\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7157 - val_loss: 0.6815\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7127 - val_loss: 0.6792\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7095 - val_loss: 0.6769\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7064 - val_loss: 0.6745\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7031 - val_loss: 0.6719\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6997 - val_loss: 0.6692\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6960 - val_loss: 0.6664\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6922 - val_loss: 0.6634\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.6882 - val_loss: 0.6604\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6840 - val_loss: 0.6571\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6795 - val_loss: 0.6537\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6746 - val_loss: 0.6501\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6692 - val_loss: 0.6462\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6633 - val_loss: 0.6419\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6568 - val_loss: 0.6376\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6494 - val_loss: 0.6338\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6410 - val_loss: 0.6313\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6316 - val_loss: 0.6310\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6218 - val_loss: 0.6395\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.6129 - val_loss: 0.6675\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6097 - val_loss: 0.6943\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6062 - val_loss: 0.6811\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.6003 - val_loss: 0.6599\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5960 - val_loss: 0.6476\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5922 - val_loss: 0.6429\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.5881 - val_loss: 0.6429\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5839 - val_loss: 0.6455\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.5799 - val_loss: 0.6476\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.5761 - val_loss: 0.6467\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5722 - val_loss: 0.6430\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.5682 - val_loss: 0.6382\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.5643 - val_loss: 0.6341\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.5606 - val_loss: 0.6311\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5568 - val_loss: 0.6290\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5529 - val_loss: 0.6275\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.5491 - val_loss: 0.6256\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.5452 - val_loss: 0.6232\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.5411 - val_loss: 0.6205\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5368 - val_loss: 0.6175\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.5319 - val_loss: 0.6143\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.5257 - val_loss: 0.6110\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.5185 - val_loss: 0.6083\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.5133 - val_loss: 0.6063\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.5101 - val_loss: 0.6036\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_65 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_64 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 252ms/step - loss: 0.8153 - val_loss: 0.7556\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8138 - val_loss: 0.7544\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8123 - val_loss: 0.7533\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8108 - val_loss: 0.7522\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.8093 - val_loss: 0.7511\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8078 - val_loss: 0.7500\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8064 - val_loss: 0.7489\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8049 - val_loss: 0.7478\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8035 - val_loss: 0.7468\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8020 - val_loss: 0.7457\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8006 - val_loss: 0.7446\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7992 - val_loss: 0.7436\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7977 - val_loss: 0.7425\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7963 - val_loss: 0.7414\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.7948 - val_loss: 0.7403\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7933 - val_loss: 0.7392\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7919 - val_loss: 0.7381\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.7904 - val_loss: 0.7370\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7888 - val_loss: 0.7359\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7873 - val_loss: 0.7348\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7858 - val_loss: 0.7337\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7842 - val_loss: 0.7325\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7826 - val_loss: 0.7314\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7810 - val_loss: 0.7302\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7794 - val_loss: 0.7291\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7778 - val_loss: 0.7279\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7762 - val_loss: 0.7267\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7745 - val_loss: 0.7255\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7728 - val_loss: 0.7243\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7711 - val_loss: 0.7231\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7693 - val_loss: 0.7219\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7675 - val_loss: 0.7206\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7657 - val_loss: 0.7193\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7638 - val_loss: 0.7180\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7619 - val_loss: 0.7167\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7599 - val_loss: 0.7153\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7579 - val_loss: 0.7140\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7558 - val_loss: 0.7126\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7536 - val_loss: 0.7111\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.7513 - val_loss: 0.7097\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7490 - val_loss: 0.7082\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7466 - val_loss: 0.7066\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7441 - val_loss: 0.7050\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7414 - val_loss: 0.7034\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7387 - val_loss: 0.7018\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7358 - val_loss: 0.7001\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7327 - val_loss: 0.6983\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7294 - val_loss: 0.6965\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7260 - val_loss: 0.6947\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7222 - val_loss: 0.6927\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7182 - val_loss: 0.6908\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7138 - val_loss: 0.6887\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7090 - val_loss: 0.6866\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7036 - val_loss: 0.6843\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6976 - val_loss: 0.6820\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6913 - val_loss: 0.6796\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6847 - val_loss: 0.6771\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6788 - val_loss: 0.6746\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.6735 - val_loss: 0.6723\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6693 - val_loss: 0.6700\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6664 - val_loss: 0.6681\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6640 - val_loss: 0.6665\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6615 - val_loss: 0.6652\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6590 - val_loss: 0.6641\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6568 - val_loss: 0.6630\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6548 - val_loss: 0.6619\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6528 - val_loss: 0.6607\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.6506 - val_loss: 0.6594\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6484 - val_loss: 0.6580\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.6460 - val_loss: 0.6566\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6436 - val_loss: 0.6551\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.6412 - val_loss: 0.6536\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6389 - val_loss: 0.6522\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6367 - val_loss: 0.6509\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6346 - val_loss: 0.6495\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6325 - val_loss: 0.6481\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6304 - val_loss: 0.6467\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6284 - val_loss: 0.6452\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6263 - val_loss: 0.6437\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.6243 - val_loss: 0.6422\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6222 - val_loss: 0.6407\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6202 - val_loss: 0.6392\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6182 - val_loss: 0.6376\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6161 - val_loss: 0.6360\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6141 - val_loss: 0.6343\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6120 - val_loss: 0.6326\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6098 - val_loss: 0.6309\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6077 - val_loss: 0.6292\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.6055 - val_loss: 0.6274\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6034 - val_loss: 0.6256\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6011 - val_loss: 0.6237\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5989 - val_loss: 0.6218\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.5966 - val_loss: 0.6198\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.5943 - val_loss: 0.6178\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.5919 - val_loss: 0.6157\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5894 - val_loss: 0.6136\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5869 - val_loss: 0.6113\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.5843 - val_loss: 0.6091\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.5816 - val_loss: 0.6068\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.5788 - val_loss: 0.6044\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_66 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_65 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 267ms/step - loss: 0.8305 - val_loss: 0.7623\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.8291 - val_loss: 0.7611\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8277 - val_loss: 0.7599\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.8264 - val_loss: 0.7587\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.8250 - val_loss: 0.7575\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.8236 - val_loss: 0.7562\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8222 - val_loss: 0.7550\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.8208 - val_loss: 0.7537\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8194 - val_loss: 0.7525\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.8179 - val_loss: 0.7512\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8165 - val_loss: 0.7499\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8150 - val_loss: 0.7485\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8135 - val_loss: 0.7472\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8120 - val_loss: 0.7459\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8105 - val_loss: 0.7445\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8090 - val_loss: 0.7431\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.8074 - val_loss: 0.7417\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.8058 - val_loss: 0.7402\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8042 - val_loss: 0.7388\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.8026 - val_loss: 0.7373\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.8009 - val_loss: 0.7358\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7992 - val_loss: 0.7342\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7975 - val_loss: 0.7326\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.7957 - val_loss: 0.7310\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7938 - val_loss: 0.7293\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7919 - val_loss: 0.7275\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.7899 - val_loss: 0.7256\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7879 - val_loss: 0.7237\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7857 - val_loss: 0.7217\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7835 - val_loss: 0.7196\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7812 - val_loss: 0.7175\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.7787 - val_loss: 0.7152\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.7761 - val_loss: 0.7128\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7734 - val_loss: 0.7103\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7706 - val_loss: 0.7078\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7676 - val_loss: 0.7051\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7645 - val_loss: 0.7024\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7612 - val_loss: 0.6995\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.7577 - val_loss: 0.6965\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7540 - val_loss: 0.6934\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7500 - val_loss: 0.6902\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7458 - val_loss: 0.6870\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7413 - val_loss: 0.6835\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7363 - val_loss: 0.6799\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.7310 - val_loss: 0.6762\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7250 - val_loss: 0.6725\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7184 - val_loss: 0.6689\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.7109 - val_loss: 0.6653\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7025 - val_loss: 0.6626\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6932 - val_loss: 0.6611\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6826 - val_loss: 0.6616\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6717 - val_loss: 0.6657\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6624 - val_loss: 0.6734\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6557 - val_loss: 0.6845\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6513 - val_loss: 0.6925\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6469 - val_loss: 0.6906\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6412 - val_loss: 0.6823\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6354 - val_loss: 0.6738\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6297 - val_loss: 0.6672\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6239 - val_loss: 0.6625\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6180 - val_loss: 0.6591\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6121 - val_loss: 0.6567\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6071 - val_loss: 0.6550\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6024 - val_loss: 0.6538\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5985 - val_loss: 0.6523\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.5949 - val_loss: 0.6502\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5913 - val_loss: 0.6475\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.5878 - val_loss: 0.6445\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.5842 - val_loss: 0.6416\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.5808 - val_loss: 0.6389\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5772 - val_loss: 0.6364\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5737 - val_loss: 0.6341\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.5700 - val_loss: 0.6320\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5663 - val_loss: 0.6300\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.5626 - val_loss: 0.6282\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5587 - val_loss: 0.6266\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5547 - val_loss: 0.6255\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.5507 - val_loss: 0.6249\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5467 - val_loss: 0.6246\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.5428 - val_loss: 0.6244\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.5390 - val_loss: 0.6237\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.5352 - val_loss: 0.6223\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.5314 - val_loss: 0.6205\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.5277 - val_loss: 0.6187\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.5242 - val_loss: 0.6171\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5209 - val_loss: 0.6156\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5177 - val_loss: 0.6141\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5145 - val_loss: 0.6126\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5114 - val_loss: 0.6109\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.5084 - val_loss: 0.6092\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5053 - val_loss: 0.6077\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5023 - val_loss: 0.6062\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.4994 - val_loss: 0.6046\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.4963 - val_loss: 0.6031\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.4933 - val_loss: 0.6015\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.4902 - val_loss: 0.5997\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.4872 - val_loss: 0.5974\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.4841 - val_loss: 0.5947\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.4810 - val_loss: 0.5919\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.4779 - val_loss: 0.5895\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_67 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_66 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 237ms/step - loss: 0.8646 - val_loss: 0.7927\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.8625 - val_loss: 0.7910\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8605 - val_loss: 0.7893\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.8584 - val_loss: 0.7876\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8564 - val_loss: 0.7859\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8544 - val_loss: 0.7841\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.8523 - val_loss: 0.7824\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8502 - val_loss: 0.7807\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8482 - val_loss: 0.7789\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8461 - val_loss: 0.7771\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8440 - val_loss: 0.7754\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.8419 - val_loss: 0.7736\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8397 - val_loss: 0.7718\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.8376 - val_loss: 0.7699\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8354 - val_loss: 0.7681\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.8332 - val_loss: 0.7662\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8310 - val_loss: 0.7643\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.8288 - val_loss: 0.7624\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.8265 - val_loss: 0.7605\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.8242 - val_loss: 0.7585\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8219 - val_loss: 0.7565\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8195 - val_loss: 0.7545\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8171 - val_loss: 0.7524\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8146 - val_loss: 0.7503\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.8121 - val_loss: 0.7482\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8096 - val_loss: 0.7460\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8069 - val_loss: 0.7438\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8043 - val_loss: 0.7415\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8016 - val_loss: 0.7392\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7988 - val_loss: 0.7369\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7959 - val_loss: 0.7345\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7930 - val_loss: 0.7320\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.7900 - val_loss: 0.7294\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7869 - val_loss: 0.7268\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7837 - val_loss: 0.7241\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7804 - val_loss: 0.7214\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.7770 - val_loss: 0.7185\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.7735 - val_loss: 0.7155\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.7699 - val_loss: 0.7125\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7661 - val_loss: 0.7093\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.7622 - val_loss: 0.7060\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7581 - val_loss: 0.7025\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.7538 - val_loss: 0.6989\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7493 - val_loss: 0.6952\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7446 - val_loss: 0.6913\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7396 - val_loss: 0.6871\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7343 - val_loss: 0.6828\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7287 - val_loss: 0.6782\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7227 - val_loss: 0.6733\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7163 - val_loss: 0.6681\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7093 - val_loss: 0.6627\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7017 - val_loss: 0.6570\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.6934 - val_loss: 0.6508\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6841 - val_loss: 0.6441\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.6738 - val_loss: 0.6370\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.6619 - val_loss: 0.6297\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6483 - val_loss: 0.6226\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6323 - val_loss: 0.6179\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.6132 - val_loss: 0.6208\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.5913 - val_loss: 0.6400\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.5737 - val_loss: 0.6936\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5740 - val_loss: 0.7278\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5650 - val_loss: 0.6896\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5552 - val_loss: 0.6591\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5497 - val_loss: 0.6454\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5446 - val_loss: 0.6417\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5387 - val_loss: 0.6439\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5331 - val_loss: 0.6492\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5283 - val_loss: 0.6540\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5241 - val_loss: 0.6545\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5200 - val_loss: 0.6500\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5161 - val_loss: 0.6439\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.5125 - val_loss: 0.6390\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.5092 - val_loss: 0.6360\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.5063 - val_loss: 0.6345\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5035 - val_loss: 0.6335\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5007 - val_loss: 0.6323\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.4980 - val_loss: 0.6302\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.4953 - val_loss: 0.6275\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.4926 - val_loss: 0.6248\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.4901 - val_loss: 0.6222\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.4875 - val_loss: 0.6197\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.4849 - val_loss: 0.6174\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.4823 - val_loss: 0.6152\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.4796 - val_loss: 0.6131\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.4768 - val_loss: 0.6112\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.4739 - val_loss: 0.6092\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.4710 - val_loss: 0.6070\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.4677 - val_loss: 0.6047\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.4644 - val_loss: 0.6025\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.4610 - val_loss: 0.6003\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.4576 - val_loss: 0.5981\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.4540 - val_loss: 0.5958\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.4505 - val_loss: 0.5936\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.4469 - val_loss: 0.5914\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.4434 - val_loss: 0.5893\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.4400 - val_loss: 0.5874\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.4368 - val_loss: 0.5856\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.4337 - val_loss: 0.5839\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.4308 - val_loss: 0.5822\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_68 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_67 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 229ms/step - loss: 0.8490 - val_loss: 0.7792\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8475 - val_loss: 0.7780\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8461 - val_loss: 0.7768\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8447 - val_loss: 0.7756\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8433 - val_loss: 0.7744\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8419 - val_loss: 0.7732\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8404 - val_loss: 0.7720\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8390 - val_loss: 0.7708\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8377 - val_loss: 0.7697\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8363 - val_loss: 0.7685\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8349 - val_loss: 0.7674\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8336 - val_loss: 0.7662\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8322 - val_loss: 0.7651\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8309 - val_loss: 0.7639\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.8295 - val_loss: 0.7628\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.8281 - val_loss: 0.7616\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8268 - val_loss: 0.7604\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8254 - val_loss: 0.7592\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.8240 - val_loss: 0.7580\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.8227 - val_loss: 0.7568\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.8213 - val_loss: 0.7556\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.8198 - val_loss: 0.7544\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.8184 - val_loss: 0.7532\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8170 - val_loss: 0.7519\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.8155 - val_loss: 0.7507\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8140 - val_loss: 0.7494\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8125 - val_loss: 0.7481\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8110 - val_loss: 0.7467\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8094 - val_loss: 0.7454\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 0.8079 - val_loss: 0.7441\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8063 - val_loss: 0.7427\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8046 - val_loss: 0.7413\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8030 - val_loss: 0.7399\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8013 - val_loss: 0.7384\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7996 - val_loss: 0.7369\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7978 - val_loss: 0.7354\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7961 - val_loss: 0.7339\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7943 - val_loss: 0.7323\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7924 - val_loss: 0.7307\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7905 - val_loss: 0.7291\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.7885 - val_loss: 0.7274\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.7866 - val_loss: 0.7257\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7845 - val_loss: 0.7240\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7824 - val_loss: 0.7223\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7803 - val_loss: 0.7205\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7780 - val_loss: 0.7187\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7757 - val_loss: 0.7169\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.7733 - val_loss: 0.7151\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7709 - val_loss: 0.7131\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.7683 - val_loss: 0.7112\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.7656 - val_loss: 0.7092\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7628 - val_loss: 0.7071\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7599 - val_loss: 0.7049\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7568 - val_loss: 0.7027\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7534 - val_loss: 0.7003\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.7499 - val_loss: 0.6979\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7462 - val_loss: 0.6954\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7423 - val_loss: 0.6929\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7380 - val_loss: 0.6902\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.7334 - val_loss: 0.6874\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7282 - val_loss: 0.6845\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7224 - val_loss: 0.6815\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.7174 - val_loss: 0.6785\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7132 - val_loss: 0.6756\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7079 - val_loss: 0.6728\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7030 - val_loss: 0.6701\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6980 - val_loss: 0.6674\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6922 - val_loss: 0.6647\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6860 - val_loss: 0.6628\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6791 - val_loss: 0.6620\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.6716 - val_loss: 0.6629\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6635 - val_loss: 0.6733\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6552 - val_loss: 0.7504\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 192ms/step - loss: 0.6484 - val_loss: 0.9989\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6470 - val_loss: 1.0787\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6410 - val_loss: 0.9275\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6362 - val_loss: 0.8230\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.6324 - val_loss: 0.7891\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6286 - val_loss: 0.7953\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6244 - val_loss: 0.8253\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.6203 - val_loss: 0.8570\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.6165 - val_loss: 0.8673\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6126 - val_loss: 0.8524\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.6087 - val_loss: 0.8252\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6048 - val_loss: 0.8017\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.6010 - val_loss: 0.7876\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.5973 - val_loss: 0.7812\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.5936 - val_loss: 0.7780\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.5899 - val_loss: 0.7752\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5863 - val_loss: 0.7675\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5825 - val_loss: 0.7552\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5788 - val_loss: 0.7447\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5751 - val_loss: 0.7374\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5714 - val_loss: 0.7319\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.5676 - val_loss: 0.7269\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.5638 - val_loss: 0.7217\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5599 - val_loss: 0.7161\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.5559 - val_loss: 0.7102\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.5518 - val_loss: 0.7043\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5477 - val_loss: 0.6980\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_69 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_68 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 244ms/step - loss: 0.8125 - val_loss: 0.7484\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8109 - val_loss: 0.7471\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8094 - val_loss: 0.7459\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8079 - val_loss: 0.7445\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8063 - val_loss: 0.7432\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8048 - val_loss: 0.7419\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8032 - val_loss: 0.7406\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.8016 - val_loss: 0.7393\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8001 - val_loss: 0.7380\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7985 - val_loss: 0.7367\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7969 - val_loss: 0.7353\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7953 - val_loss: 0.7340\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7937 - val_loss: 0.7327\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7920 - val_loss: 0.7313\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7904 - val_loss: 0.7300\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7888 - val_loss: 0.7286\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7871 - val_loss: 0.7272\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7855 - val_loss: 0.7258\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7838 - val_loss: 0.7244\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7821 - val_loss: 0.7230\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7804 - val_loss: 0.7216\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7787 - val_loss: 0.7202\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.7770 - val_loss: 0.7188\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7753 - val_loss: 0.7173\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7735 - val_loss: 0.7159\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.7717 - val_loss: 0.7144\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7699 - val_loss: 0.7129\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7680 - val_loss: 0.7113\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7662 - val_loss: 0.7098\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7642 - val_loss: 0.7082\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7623 - val_loss: 0.7065\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7603 - val_loss: 0.7049\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7582 - val_loss: 0.7032\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.7561 - val_loss: 0.7015\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.7540 - val_loss: 0.6997\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7517 - val_loss: 0.6979\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.7495 - val_loss: 0.6960\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.7471 - val_loss: 0.6941\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7447 - val_loss: 0.6921\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7422 - val_loss: 0.6901\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7396 - val_loss: 0.6880\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.7370 - val_loss: 0.6860\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.7342 - val_loss: 0.6838\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7313 - val_loss: 0.6816\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7284 - val_loss: 0.6794\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7252 - val_loss: 0.6771\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.7220 - val_loss: 0.6748\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7185 - val_loss: 0.6723\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7149 - val_loss: 0.6698\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7111 - val_loss: 0.6672\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7071 - val_loss: 0.6644\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7027 - val_loss: 0.6616\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 194ms/step - loss: 0.6981 - val_loss: 0.6587\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6931 - val_loss: 0.6558\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6876 - val_loss: 0.6527\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6816 - val_loss: 0.6494\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6749 - val_loss: 0.6461\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6677 - val_loss: 0.6427\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6601 - val_loss: 0.6392\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6530 - val_loss: 0.6358\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.6469 - val_loss: 0.6325\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6416 - val_loss: 0.6294\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6363 - val_loss: 0.6267\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6309 - val_loss: 0.6245\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6255 - val_loss: 0.6230\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6203 - val_loss: 0.6225\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6154 - val_loss: 0.6226\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6108 - val_loss: 0.6233\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6066 - val_loss: 0.6246\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.6024 - val_loss: 0.6260\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5983 - val_loss: 0.6269\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5941 - val_loss: 0.6271\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5900 - val_loss: 0.6268\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5858 - val_loss: 0.6262\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.5818 - val_loss: 0.6255\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.5777 - val_loss: 0.6248\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5738 - val_loss: 0.6238\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.5699 - val_loss: 0.6226\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.5660 - val_loss: 0.6213\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.5621 - val_loss: 0.6201\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5583 - val_loss: 0.6189\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.5544 - val_loss: 0.6174\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5506 - val_loss: 0.6159\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5468 - val_loss: 0.6143\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.5431 - val_loss: 0.6128\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 193ms/step - loss: 0.5394 - val_loss: 0.6114\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.5357 - val_loss: 0.6098\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5321 - val_loss: 0.6080\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5285 - val_loss: 0.6058\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.5249 - val_loss: 0.6032\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.5214 - val_loss: 0.6004\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.5180 - val_loss: 0.5976\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5146 - val_loss: 0.5949\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5112 - val_loss: 0.5923\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5078 - val_loss: 0.5896\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5045 - val_loss: 0.5866\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5012 - val_loss: 0.5838\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.4980 - val_loss: 0.5812\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.4948 - val_loss: 0.5791\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.4917 - val_loss: 0.5771\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_70 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_69 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 245ms/step - loss: 0.8311 - val_loss: 0.7669\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8296 - val_loss: 0.7656\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8281 - val_loss: 0.7644\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8266 - val_loss: 0.7631\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8251 - val_loss: 0.7618\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8236 - val_loss: 0.7606\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.8222 - val_loss: 0.7593\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8207 - val_loss: 0.7581\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8192 - val_loss: 0.7568\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8178 - val_loss: 0.7556\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8163 - val_loss: 0.7543\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8148 - val_loss: 0.7531\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8134 - val_loss: 0.7518\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8119 - val_loss: 0.7506\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8104 - val_loss: 0.7493\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8090 - val_loss: 0.7481\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8075 - val_loss: 0.7468\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8060 - val_loss: 0.7455\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8045 - val_loss: 0.7442\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.8030 - val_loss: 0.7429\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8015 - val_loss: 0.7416\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7999 - val_loss: 0.7402\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7984 - val_loss: 0.7388\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7968 - val_loss: 0.7374\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7952 - val_loss: 0.7360\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7935 - val_loss: 0.7345\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7919 - val_loss: 0.7331\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7902 - val_loss: 0.7315\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.7884 - val_loss: 0.7300\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7867 - val_loss: 0.7284\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7848 - val_loss: 0.7268\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7830 - val_loss: 0.7251\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7811 - val_loss: 0.7234\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.7791 - val_loss: 0.7216\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7771 - val_loss: 0.7197\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7751 - val_loss: 0.7178\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7730 - val_loss: 0.7159\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7708 - val_loss: 0.7138\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7685 - val_loss: 0.7117\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7661 - val_loss: 0.7095\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7637 - val_loss: 0.7071\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7611 - val_loss: 0.7048\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7584 - val_loss: 0.7022\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7556 - val_loss: 0.6997\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7527 - val_loss: 0.6969\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7495 - val_loss: 0.6940\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.7462 - val_loss: 0.6909\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7426 - val_loss: 0.6877\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7386 - val_loss: 0.6843\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7343 - val_loss: 0.6807\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7294 - val_loss: 0.6770\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7238 - val_loss: 0.6735\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7173 - val_loss: 0.6708\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7096 - val_loss: 0.6687\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7007 - val_loss: 0.6690\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6912 - val_loss: 0.6799\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.6827 - val_loss: 0.7093\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6792 - val_loss: 0.7485\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.6780 - val_loss: 0.7460\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6732 - val_loss: 0.7200\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6693 - val_loss: 0.7018\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6665 - val_loss: 0.6929\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6636 - val_loss: 0.6902\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6605 - val_loss: 0.6914\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6572 - val_loss: 0.6945\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.6540 - val_loss: 0.6969\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6508 - val_loss: 0.6964\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6476 - val_loss: 0.6931\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6442 - val_loss: 0.6883\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.6408 - val_loss: 0.6835\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6374 - val_loss: 0.6795\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6339 - val_loss: 0.6764\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6302 - val_loss: 0.6737\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6265 - val_loss: 0.6710\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6225 - val_loss: 0.6677\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6185 - val_loss: 0.6636\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.6142 - val_loss: 0.6589\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.6096 - val_loss: 0.6538\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6048 - val_loss: 0.6486\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5995 - val_loss: 0.6433\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.5939 - val_loss: 0.6378\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5877 - val_loss: 0.6319\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.5811 - val_loss: 0.6255\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5741 - val_loss: 0.6186\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5667 - val_loss: 0.6115\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.5590 - val_loss: 0.6045\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.5508 - val_loss: 0.5986\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.5426 - val_loss: 0.5940\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 0.5357 - val_loss: 0.5909\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5295 - val_loss: 0.5883\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5235 - val_loss: 0.5854\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.5179 - val_loss: 0.5823\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.5124 - val_loss: 0.5788\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5069 - val_loss: 0.5751\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5013 - val_loss: 0.5711\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.4958 - val_loss: 0.5671\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 0.4904 - val_loss: 0.5632\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.4851 - val_loss: 0.5597\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.4800 - val_loss: 0.5565\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.4751 - val_loss: 0.5532\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_71 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_70 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 245ms/step - loss: 0.8253 - val_loss: 0.7605\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8242 - val_loss: 0.7595\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.8231 - val_loss: 0.7585\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.8220 - val_loss: 0.7576\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8209 - val_loss: 0.7566\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8198 - val_loss: 0.7556\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 0.8187 - val_loss: 0.7547\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8176 - val_loss: 0.7537\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.8165 - val_loss: 0.7527\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8153 - val_loss: 0.7517\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8142 - val_loss: 0.7508\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8131 - val_loss: 0.7498\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.8119 - val_loss: 0.7488\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8108 - val_loss: 0.7477\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8096 - val_loss: 0.7467\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8084 - val_loss: 0.7457\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8072 - val_loss: 0.7447\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8060 - val_loss: 0.7436\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8048 - val_loss: 0.7426\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.8035 - val_loss: 0.7415\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8023 - val_loss: 0.7405\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8010 - val_loss: 0.7394\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7997 - val_loss: 0.7383\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7984 - val_loss: 0.7372\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7970 - val_loss: 0.7360\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7957 - val_loss: 0.7349\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.7943 - val_loss: 0.7337\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7929 - val_loss: 0.7326\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7914 - val_loss: 0.7314\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7900 - val_loss: 0.7302\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.7885 - val_loss: 0.7290\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7870 - val_loss: 0.7277\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7854 - val_loss: 0.7264\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7838 - val_loss: 0.7252\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7822 - val_loss: 0.7239\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.7806 - val_loss: 0.7225\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7789 - val_loss: 0.7212\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.7771 - val_loss: 0.7198\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7754 - val_loss: 0.7184\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7735 - val_loss: 0.7169\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.7717 - val_loss: 0.7154\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7698 - val_loss: 0.7139\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7678 - val_loss: 0.7124\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7658 - val_loss: 0.7108\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7637 - val_loss: 0.7092\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7615 - val_loss: 0.7076\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7593 - val_loss: 0.7059\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7570 - val_loss: 0.7042\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.7546 - val_loss: 0.7024\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7522 - val_loss: 0.7006\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7496 - val_loss: 0.6987\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7470 - val_loss: 0.6968\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7442 - val_loss: 0.6948\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7412 - val_loss: 0.6928\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7382 - val_loss: 0.6907\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7349 - val_loss: 0.6885\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7314 - val_loss: 0.6862\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7277 - val_loss: 0.6839\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7236 - val_loss: 0.6815\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7191 - val_loss: 0.6789\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 196ms/step - loss: 0.7142 - val_loss: 0.6763\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7085 - val_loss: 0.6737\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.7018 - val_loss: 0.6708\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6937 - val_loss: 0.6678\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6850 - val_loss: 0.6648\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6793 - val_loss: 0.6619\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6758 - val_loss: 0.6595\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6707 - val_loss: 0.6579\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6655 - val_loss: 0.6567\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6610 - val_loss: 0.6560\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6565 - val_loss: 0.6557\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.6516 - val_loss: 0.6559\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6462 - val_loss: 0.6583\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6406 - val_loss: 0.6690\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6349 - val_loss: 0.6974\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6299 - val_loss: 0.7663\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.6260 - val_loss: 0.8562\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6232 - val_loss: 0.9112\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6206 - val_loss: 0.9043\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6174 - val_loss: 0.8630\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6143 - val_loss: 0.8253\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6116 - val_loss: 0.8032\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6089 - val_loss: 0.7961\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6062 - val_loss: 0.8005\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6035 - val_loss: 0.8104\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6008 - val_loss: 0.8177\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5982 - val_loss: 0.8186\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.5955 - val_loss: 0.8139\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5929 - val_loss: 0.8065\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.5902 - val_loss: 0.8009\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5876 - val_loss: 0.7981\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.5849 - val_loss: 0.7966\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.5823 - val_loss: 0.7964\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.5797 - val_loss: 0.7951\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5770 - val_loss: 0.7902\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.5743 - val_loss: 0.7835\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.5716 - val_loss: 0.7785\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.5689 - val_loss: 0.7755\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.5662 - val_loss: 0.7740\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.5634 - val_loss: 0.7734\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_72 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_71 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 265ms/step - loss: 0.8440 - val_loss: 0.7808\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.8420 - val_loss: 0.7793\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.8400 - val_loss: 0.7777\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.8380 - val_loss: 0.7761\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8360 - val_loss: 0.7745\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.8339 - val_loss: 0.7729\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8318 - val_loss: 0.7713\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8296 - val_loss: 0.7696\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8274 - val_loss: 0.7678\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8251 - val_loss: 0.7660\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8227 - val_loss: 0.7642\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8203 - val_loss: 0.7623\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8178 - val_loss: 0.7604\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8152 - val_loss: 0.7586\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8126 - val_loss: 0.7566\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8099 - val_loss: 0.7547\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8072 - val_loss: 0.7527\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8043 - val_loss: 0.7507\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8013 - val_loss: 0.7487\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7982 - val_loss: 0.7466\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7950 - val_loss: 0.7446\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7916 - val_loss: 0.7424\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7880 - val_loss: 0.7403\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7842 - val_loss: 0.7381\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7802 - val_loss: 0.7359\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.7759 - val_loss: 0.7336\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7710 - val_loss: 0.7312\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7656 - val_loss: 0.7288\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7595 - val_loss: 0.7263\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.7533 - val_loss: 0.7238\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7475 - val_loss: 0.7213\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7426 - val_loss: 0.7188\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.7411 - val_loss: 0.7168\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7374 - val_loss: 0.7156\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 194ms/step - loss: 0.7349 - val_loss: 0.7145\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.7333 - val_loss: 0.7132\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7314 - val_loss: 0.7117\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.7291 - val_loss: 0.7101\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.7266 - val_loss: 0.7084\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.7242 - val_loss: 0.7067\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7218 - val_loss: 0.7053\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7195 - val_loss: 0.7039\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.7174 - val_loss: 0.7024\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7151 - val_loss: 0.7008\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7127 - val_loss: 0.6992\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7103 - val_loss: 0.6975\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7079 - val_loss: 0.6960\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7055 - val_loss: 0.6944\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7031 - val_loss: 0.6927\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7007 - val_loss: 0.6910\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6981 - val_loss: 0.6893\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6955 - val_loss: 0.6876\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.6929 - val_loss: 0.6860\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6905 - val_loss: 0.6842\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.6879 - val_loss: 0.6824\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.6853 - val_loss: 0.6806\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.6826 - val_loss: 0.6787\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6799 - val_loss: 0.6769\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6773 - val_loss: 0.6750\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6745 - val_loss: 0.6731\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.6717 - val_loss: 0.6711\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.6688 - val_loss: 0.6690\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6658 - val_loss: 0.6670\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.6629 - val_loss: 0.6649\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6599 - val_loss: 0.6629\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6570 - val_loss: 0.6609\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6541 - val_loss: 0.6588\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6512 - val_loss: 0.6568\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6484 - val_loss: 0.6547\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6457 - val_loss: 0.6527\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.6430 - val_loss: 0.6508\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6405 - val_loss: 0.6488\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6380 - val_loss: 0.6468\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6354 - val_loss: 0.6447\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6328 - val_loss: 0.6426\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6301 - val_loss: 0.6404\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6273 - val_loss: 0.6381\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6246 - val_loss: 0.6357\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.6217 - val_loss: 0.6333\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6189 - val_loss: 0.6308\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.6160 - val_loss: 0.6281\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6130 - val_loss: 0.6252\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6098 - val_loss: 0.6222\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6064 - val_loss: 0.6193\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6028 - val_loss: 0.6166\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5990 - val_loss: 0.6152\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.5948 - val_loss: 0.6145\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5903 - val_loss: 0.6157\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.5852 - val_loss: 0.6256\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5796 - val_loss: 0.6610\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.5738 - val_loss: 0.7574\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5689 - val_loss: 0.9343\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.5660 - val_loss: 1.0965\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5634 - val_loss: 1.0656\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.5595 - val_loss: 0.9535\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5563 - val_loss: 0.8884\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5533 - val_loss: 0.8731\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.5501 - val_loss: 0.8923\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.5469 - val_loss: 0.9351\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.5437 - val_loss: 0.9701\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_73 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_72 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 261ms/step - loss: 0.8541 - val_loss: 0.7884\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8527 - val_loss: 0.7872\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.8512 - val_loss: 0.7860\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8498 - val_loss: 0.7847\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8484 - val_loss: 0.7835\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8470 - val_loss: 0.7823\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.8456 - val_loss: 0.7811\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8442 - val_loss: 0.7799\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8428 - val_loss: 0.7787\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.8414 - val_loss: 0.7775\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.8400 - val_loss: 0.7763\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8386 - val_loss: 0.7751\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.8372 - val_loss: 0.7739\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8358 - val_loss: 0.7728\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.8344 - val_loss: 0.7716\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 193ms/step - loss: 0.8330 - val_loss: 0.7704\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.8316 - val_loss: 0.7692\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8302 - val_loss: 0.7680\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8288 - val_loss: 0.7668\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.8274 - val_loss: 0.7656\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.8259 - val_loss: 0.7644\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.8245 - val_loss: 0.7632\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 196ms/step - loss: 0.8230 - val_loss: 0.7620\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.8215 - val_loss: 0.7608\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8200 - val_loss: 0.7596\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.8185 - val_loss: 0.7584\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8170 - val_loss: 0.7572\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8154 - val_loss: 0.7559\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8138 - val_loss: 0.7546\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.8122 - val_loss: 0.7534\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8106 - val_loss: 0.7521\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.8089 - val_loss: 0.7508\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.8072 - val_loss: 0.7495\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.8055 - val_loss: 0.7481\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 196ms/step - loss: 0.8037 - val_loss: 0.7468\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8018 - val_loss: 0.7454\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7999 - val_loss: 0.7440\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.7979 - val_loss: 0.7425\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.7959 - val_loss: 0.7410\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7938 - val_loss: 0.7395\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7916 - val_loss: 0.7380\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.7893 - val_loss: 0.7364\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 193ms/step - loss: 0.7868 - val_loss: 0.7347\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7842 - val_loss: 0.7330\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7815 - val_loss: 0.7313\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7784 - val_loss: 0.7294\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7751 - val_loss: 0.7275\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7713 - val_loss: 0.7254\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7671 - val_loss: 0.7233\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7622 - val_loss: 0.7210\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7565 - val_loss: 0.7185\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7496 - val_loss: 0.7159\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7408 - val_loss: 0.7130\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.7290 - val_loss: 0.7098\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7130 - val_loss: 0.7062\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6983 - val_loss: 0.7025\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6988 - val_loss: 0.7001\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6877 - val_loss: 0.6994\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.6847 - val_loss: 0.6986\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 194ms/step - loss: 0.6828 - val_loss: 0.6971\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6788 - val_loss: 0.6951\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 192ms/step - loss: 0.6752 - val_loss: 0.6931\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6726 - val_loss: 0.6915\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6700 - val_loss: 0.6902\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6679 - val_loss: 0.6890\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6662 - val_loss: 0.6877\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6643 - val_loss: 0.6861\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.6622 - val_loss: 0.6845\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6600 - val_loss: 0.6828\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.6579 - val_loss: 0.6813\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6558 - val_loss: 0.6798\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6537 - val_loss: 0.6784\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6516 - val_loss: 0.6768\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6494 - val_loss: 0.6752\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.6470 - val_loss: 0.6736\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6446 - val_loss: 0.6719\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6422 - val_loss: 0.6703\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6397 - val_loss: 0.6687\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.6372 - val_loss: 0.6671\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6347 - val_loss: 0.6654\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.6322 - val_loss: 0.6639\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6298 - val_loss: 0.6623\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6274 - val_loss: 0.6606\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6251 - val_loss: 0.6591\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.6225 - val_loss: 0.6573\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6198 - val_loss: 0.6559\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6174 - val_loss: 0.6545\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.6149 - val_loss: 0.6536\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 194ms/step - loss: 0.6123 - val_loss: 0.6530\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6094 - val_loss: 0.6535\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6066 - val_loss: 0.6548\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6036 - val_loss: 0.6577\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6004 - val_loss: 0.6628\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.5976 - val_loss: 0.6700\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5953 - val_loss: 0.6778\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.5933 - val_loss: 0.6822\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.5913 - val_loss: 0.6799\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.5891 - val_loss: 0.6739\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.5868 - val_loss: 0.6682\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 196ms/step - loss: 0.5847 - val_loss: 0.6642\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_74 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_73 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 273ms/step - loss: 0.8283 - val_loss: 0.7605\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8269 - val_loss: 0.7593\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.8255 - val_loss: 0.7580\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8241 - val_loss: 0.7567\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8226 - val_loss: 0.7554\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 0.8212 - val_loss: 0.7541\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8198 - val_loss: 0.7528\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8183 - val_loss: 0.7514\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8169 - val_loss: 0.7501\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8154 - val_loss: 0.7487\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8139 - val_loss: 0.7473\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8123 - val_loss: 0.7459\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.8108 - val_loss: 0.7444\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8091 - val_loss: 0.7429\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8075 - val_loss: 0.7414\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.8058 - val_loss: 0.7399\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8041 - val_loss: 0.7383\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8023 - val_loss: 0.7367\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8005 - val_loss: 0.7351\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7987 - val_loss: 0.7334\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7967 - val_loss: 0.7317\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7948 - val_loss: 0.7299\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7927 - val_loss: 0.7281\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.7906 - val_loss: 0.7262\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.7884 - val_loss: 0.7243\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7862 - val_loss: 0.7223\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7839 - val_loss: 0.7203\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7815 - val_loss: 0.7181\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7790 - val_loss: 0.7159\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.7765 - val_loss: 0.7136\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7738 - val_loss: 0.7113\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7711 - val_loss: 0.7088\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7682 - val_loss: 0.7063\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7652 - val_loss: 0.7036\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7621 - val_loss: 0.7009\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7589 - val_loss: 0.6980\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7555 - val_loss: 0.6949\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7519 - val_loss: 0.6918\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 195ms/step - loss: 0.7482 - val_loss: 0.6884\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 0.7442 - val_loss: 0.6849\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7400 - val_loss: 0.6814\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.7354 - val_loss: 0.6776\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 196ms/step - loss: 0.7305 - val_loss: 0.6740\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7252 - val_loss: 0.6706\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7193 - val_loss: 0.6675\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.7129 - val_loss: 0.6648\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.7058 - val_loss: 0.6629\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6981 - val_loss: 0.6643\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6902 - val_loss: 0.6709\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6824 - val_loss: 0.6948\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6759 - val_loss: 0.7489\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.6721 - val_loss: 0.8050\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6682 - val_loss: 0.8020\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6628 - val_loss: 0.7654\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6575 - val_loss: 0.7366\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6525 - val_loss: 0.7224\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6473 - val_loss: 0.7192\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6418 - val_loss: 0.7224\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6359 - val_loss: 0.7265\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6295 - val_loss: 0.7263\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6222 - val_loss: 0.7209\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6136 - val_loss: 0.7135\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6049 - val_loss: 0.7069\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.5996 - val_loss: 0.7021\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.5954 - val_loss: 0.6986\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.5899 - val_loss: 0.6955\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.5853 - val_loss: 0.6919\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.5814 - val_loss: 0.6879\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5777 - val_loss: 0.6835\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 192ms/step - loss: 0.5738 - val_loss: 0.6792\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.5697 - val_loss: 0.6753\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5659 - val_loss: 0.6719\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.5622 - val_loss: 0.6693\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5586 - val_loss: 0.6672\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.5552 - val_loss: 0.6647\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.5519 - val_loss: 0.6611\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5487 - val_loss: 0.6571\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.5454 - val_loss: 0.6535\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.5423 - val_loss: 0.6507\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.5392 - val_loss: 0.6483\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 0.5363 - val_loss: 0.6458\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.5335 - val_loss: 0.6434\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.5306 - val_loss: 0.6409\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.5277 - val_loss: 0.6382\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.5250 - val_loss: 0.6354\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.5222 - val_loss: 0.6327\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.5194 - val_loss: 0.6302\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.5166 - val_loss: 0.6279\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.5138 - val_loss: 0.6255\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5111 - val_loss: 0.6233\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5084 - val_loss: 0.6212\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.5057 - val_loss: 0.6191\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.5030 - val_loss: 0.6170\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.5004 - val_loss: 0.6149\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 194ms/step - loss: 0.4977 - val_loss: 0.6128\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.4951 - val_loss: 0.6107\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.4925 - val_loss: 0.6085\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.4899 - val_loss: 0.6062\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 194ms/step - loss: 0.4874 - val_loss: 0.6039\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.4850 - val_loss: 0.6015\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_75 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_74 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 247ms/step - loss: 0.8512 - val_loss: 0.7802\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.8499 - val_loss: 0.7791\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8485 - val_loss: 0.7780\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8472 - val_loss: 0.7769\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8459 - val_loss: 0.7758\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8446 - val_loss: 0.7747\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8432 - val_loss: 0.7736\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8419 - val_loss: 0.7725\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 194ms/step - loss: 0.8405 - val_loss: 0.7714\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.8392 - val_loss: 0.7703\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.8378 - val_loss: 0.7692\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.8364 - val_loss: 0.7680\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8350 - val_loss: 0.7669\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8337 - val_loss: 0.7658\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.8323 - val_loss: 0.7647\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.8309 - val_loss: 0.7635\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8294 - val_loss: 0.7624\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.8280 - val_loss: 0.7612\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8266 - val_loss: 0.7601\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8251 - val_loss: 0.7589\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.8236 - val_loss: 0.7578\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.8221 - val_loss: 0.7566\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8206 - val_loss: 0.7554\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8192 - val_loss: 0.7543\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.8177 - val_loss: 0.7531\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8161 - val_loss: 0.7519\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 193ms/step - loss: 0.8146 - val_loss: 0.7507\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8130 - val_loss: 0.7495\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.8115 - val_loss: 0.7483\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.8099 - val_loss: 0.7471\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.8082 - val_loss: 0.7458\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8065 - val_loss: 0.7446\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.8048 - val_loss: 0.7433\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.8030 - val_loss: 0.7420\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8011 - val_loss: 0.7407\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7992 - val_loss: 0.7394\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7971 - val_loss: 0.7380\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7950 - val_loss: 0.7366\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7928 - val_loss: 0.7352\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.7906 - val_loss: 0.7337\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7882 - val_loss: 0.7323\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.7857 - val_loss: 0.7308\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7831 - val_loss: 0.7292\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7803 - val_loss: 0.7277\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7773 - val_loss: 0.7261\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7740 - val_loss: 0.7244\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7703 - val_loss: 0.7228\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.7660 - val_loss: 0.7210\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7619 - val_loss: 0.7193\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7584 - val_loss: 0.7175\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7546 - val_loss: 0.7158\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7504 - val_loss: 0.7141\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7459 - val_loss: 0.7123\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7407 - val_loss: 0.7105\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7350 - val_loss: 0.7086\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7296 - val_loss: 0.7068\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7245 - val_loss: 0.7050\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7198 - val_loss: 0.7034\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7159 - val_loss: 0.7018\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7123 - val_loss: 0.7003\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.7090 - val_loss: 0.6988\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7059 - val_loss: 0.6973\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7031 - val_loss: 0.6959\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7004 - val_loss: 0.6945\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6979 - val_loss: 0.6932\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6954 - val_loss: 0.6918\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6930 - val_loss: 0.6904\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6908 - val_loss: 0.6891\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6886 - val_loss: 0.6878\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6864 - val_loss: 0.6864\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6841 - val_loss: 0.6851\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6819 - val_loss: 0.6838\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6798 - val_loss: 0.6824\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6777 - val_loss: 0.6810\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6756 - val_loss: 0.6797\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 0.6735 - val_loss: 0.6783\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6714 - val_loss: 0.6769\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6693 - val_loss: 0.6755\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6672 - val_loss: 0.6740\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6650 - val_loss: 0.6726\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6628 - val_loss: 0.6711\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6606 - val_loss: 0.6696\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6583 - val_loss: 0.6681\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6560 - val_loss: 0.6665\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6536 - val_loss: 0.6650\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.6513 - val_loss: 0.6634\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6488 - val_loss: 0.6617\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.6464 - val_loss: 0.6600\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6438 - val_loss: 0.6583\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.6412 - val_loss: 0.6565\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.6385 - val_loss: 0.6546\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6357 - val_loss: 0.6527\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6328 - val_loss: 0.6507\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6298 - val_loss: 0.6487\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6267 - val_loss: 0.6467\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6235 - val_loss: 0.6445\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6201 - val_loss: 0.6424\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6166 - val_loss: 0.6402\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6129 - val_loss: 0.6380\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6091 - val_loss: 0.6357\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_75\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_76 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_75 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 255ms/step - loss: 0.8643 - val_loss: 0.7937\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8629 - val_loss: 0.7924\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8615 - val_loss: 0.7912\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8602 - val_loss: 0.7900\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8589 - val_loss: 0.7887\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8575 - val_loss: 0.7875\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8562 - val_loss: 0.7863\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8548 - val_loss: 0.7850\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8535 - val_loss: 0.7838\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.8522 - val_loss: 0.7826\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8508 - val_loss: 0.7813\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8495 - val_loss: 0.7801\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8481 - val_loss: 0.7788\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8467 - val_loss: 0.7776\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8453 - val_loss: 0.7763\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 0.8439 - val_loss: 0.7750\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8425 - val_loss: 0.7738\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8411 - val_loss: 0.7725\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8397 - val_loss: 0.7712\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8383 - val_loss: 0.7699\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8368 - val_loss: 0.7686\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8353 - val_loss: 0.7673\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8338 - val_loss: 0.7660\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.8323 - val_loss: 0.7646\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8308 - val_loss: 0.7633\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8292 - val_loss: 0.7619\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8276 - val_loss: 0.7606\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8260 - val_loss: 0.7592\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.8243 - val_loss: 0.7578\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.8226 - val_loss: 0.7563\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.8209 - val_loss: 0.7549\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8191 - val_loss: 0.7534\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 194ms/step - loss: 0.8173 - val_loss: 0.7519\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.8154 - val_loss: 0.7504\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8135 - val_loss: 0.7488\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8115 - val_loss: 0.7472\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8094 - val_loss: 0.7456\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8073 - val_loss: 0.7439\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8050 - val_loss: 0.7422\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.8027 - val_loss: 0.7404\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8002 - val_loss: 0.7386\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7977 - val_loss: 0.7367\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.7950 - val_loss: 0.7348\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7921 - val_loss: 0.7328\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.7891 - val_loss: 0.7307\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7859 - val_loss: 0.7285\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7824 - val_loss: 0.7263\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7786 - val_loss: 0.7240\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7744 - val_loss: 0.7215\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.7697 - val_loss: 0.7189\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7643 - val_loss: 0.7163\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7580 - val_loss: 0.7134\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7507 - val_loss: 0.7104\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7427 - val_loss: 0.7073\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7361 - val_loss: 0.7041\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7332 - val_loss: 0.7014\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.7295 - val_loss: 0.6995\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7255 - val_loss: 0.6979\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7224 - val_loss: 0.6965\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7198 - val_loss: 0.6948\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.7171 - val_loss: 0.6928\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 0.7139 - val_loss: 0.6906\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7104 - val_loss: 0.6884\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7069 - val_loss: 0.6861\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.7034 - val_loss: 0.6840\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7000 - val_loss: 0.6820\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6967 - val_loss: 0.6801\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6933 - val_loss: 0.6782\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6900 - val_loss: 0.6762\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.6866 - val_loss: 0.6742\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6830 - val_loss: 0.6721\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6793 - val_loss: 0.6699\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6753 - val_loss: 0.6677\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.6713 - val_loss: 0.6654\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6671 - val_loss: 0.6633\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6629 - val_loss: 0.6612\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6588 - val_loss: 0.6592\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.6549 - val_loss: 0.6573\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 0.6511 - val_loss: 0.6553\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6474 - val_loss: 0.6533\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6437 - val_loss: 0.6513\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.6403 - val_loss: 0.6495\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6371 - val_loss: 0.6478\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6342 - val_loss: 0.6461\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6314 - val_loss: 0.6444\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6287 - val_loss: 0.6426\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6260 - val_loss: 0.6408\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 0.6234 - val_loss: 0.6390\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 192ms/step - loss: 0.6208 - val_loss: 0.6373\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6183 - val_loss: 0.6355\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6158 - val_loss: 0.6337\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.6132 - val_loss: 0.6318\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.6105 - val_loss: 0.6299\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6078 - val_loss: 0.6280\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.6051 - val_loss: 0.6261\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6025 - val_loss: 0.6241\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5998 - val_loss: 0.6221\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.5971 - val_loss: 0.6201\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.5944 - val_loss: 0.6180\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.5917 - val_loss: 0.6159\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_76\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_77 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_76 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 260ms/step - loss: 0.8451 - val_loss: 0.7744\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.8436 - val_loss: 0.7732\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.8420 - val_loss: 0.7719\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8405 - val_loss: 0.7707\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.8390 - val_loss: 0.7694\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8375 - val_loss: 0.7682\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8360 - val_loss: 0.7669\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.8345 - val_loss: 0.7657\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8330 - val_loss: 0.7644\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8315 - val_loss: 0.7632\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 195ms/step - loss: 0.8300 - val_loss: 0.7620\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.8285 - val_loss: 0.7608\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.8270 - val_loss: 0.7595\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.8254 - val_loss: 0.7583\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8239 - val_loss: 0.7570\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8224 - val_loss: 0.7558\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8209 - val_loss: 0.7546\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.8193 - val_loss: 0.7533\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.8178 - val_loss: 0.7521\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8162 - val_loss: 0.7508\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.8146 - val_loss: 0.7495\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.8130 - val_loss: 0.7482\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8114 - val_loss: 0.7469\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8098 - val_loss: 0.7456\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8081 - val_loss: 0.7443\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.8064 - val_loss: 0.7429\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8047 - val_loss: 0.7416\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8030 - val_loss: 0.7402\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8012 - val_loss: 0.7388\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7994 - val_loss: 0.7374\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7975 - val_loss: 0.7359\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.7956 - val_loss: 0.7344\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7936 - val_loss: 0.7329\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7916 - val_loss: 0.7313\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7895 - val_loss: 0.7298\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7873 - val_loss: 0.7281\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7851 - val_loss: 0.7264\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7827 - val_loss: 0.7247\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7802 - val_loss: 0.7229\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7776 - val_loss: 0.7210\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7748 - val_loss: 0.7191\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7718 - val_loss: 0.7170\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7686 - val_loss: 0.7149\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 193ms/step - loss: 0.7651 - val_loss: 0.7127\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.7613 - val_loss: 0.7104\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.7569 - val_loss: 0.7079\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7520 - val_loss: 0.7053\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7461 - val_loss: 0.7024\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7388 - val_loss: 0.6993\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.7291 - val_loss: 0.6960\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7158 - val_loss: 0.6923\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7004 - val_loss: 0.6885\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7028 - val_loss: 0.6861\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6882 - val_loss: 0.6863\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 0.6890 - val_loss: 0.6859\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6879 - val_loss: 0.6848\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6843 - val_loss: 0.6834\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6794 - val_loss: 0.6817\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6752 - val_loss: 0.6800\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6734 - val_loss: 0.6787\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6703 - val_loss: 0.6780\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6680 - val_loss: 0.6774\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6666 - val_loss: 0.6765\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.6647 - val_loss: 0.6754\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6628 - val_loss: 0.6743\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6611 - val_loss: 0.6732\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6593 - val_loss: 0.6724\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6578 - val_loss: 0.6715\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6563 - val_loss: 0.6705\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6547 - val_loss: 0.6695\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6532 - val_loss: 0.6685\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6517 - val_loss: 0.6676\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6503 - val_loss: 0.6666\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.6489 - val_loss: 0.6656\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6475 - val_loss: 0.6645\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6461 - val_loss: 0.6635\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6447 - val_loss: 0.6624\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.6433 - val_loss: 0.6613\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6418 - val_loss: 0.6601\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6404 - val_loss: 0.6589\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.6389 - val_loss: 0.6577\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6374 - val_loss: 0.6565\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.6359 - val_loss: 0.6553\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6344 - val_loss: 0.6541\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6329 - val_loss: 0.6528\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 0.6314 - val_loss: 0.6515\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6298 - val_loss: 0.6501\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6281 - val_loss: 0.6488\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.6265 - val_loss: 0.6474\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.6248 - val_loss: 0.6459\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.6230 - val_loss: 0.6444\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.6212 - val_loss: 0.6429\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6193 - val_loss: 0.6413\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6172 - val_loss: 0.6396\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 0.6150 - val_loss: 0.6379\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6126 - val_loss: 0.6362\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6103 - val_loss: 0.6346\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6081 - val_loss: 0.6333\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6062 - val_loss: 0.6319\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6043 - val_loss: 0.6306\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_77\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_78 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_77 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 279ms/step - loss: 0.8498 - val_loss: 0.7830\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8486 - val_loss: 0.7819\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8474 - val_loss: 0.7809\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.8463 - val_loss: 0.7798\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8451 - val_loss: 0.7787\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.8439 - val_loss: 0.7776\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.8427 - val_loss: 0.7765\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8415 - val_loss: 0.7754\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.8403 - val_loss: 0.7743\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8391 - val_loss: 0.7732\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8378 - val_loss: 0.7721\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.8366 - val_loss: 0.7710\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.8353 - val_loss: 0.7699\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8341 - val_loss: 0.7688\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.8328 - val_loss: 0.7676\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.8315 - val_loss: 0.7665\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.8302 - val_loss: 0.7653\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8289 - val_loss: 0.7641\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.8275 - val_loss: 0.7630\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8262 - val_loss: 0.7618\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8248 - val_loss: 0.7606\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8235 - val_loss: 0.7594\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8221 - val_loss: 0.7581\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.8207 - val_loss: 0.7569\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8193 - val_loss: 0.7557\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8178 - val_loss: 0.7544\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8164 - val_loss: 0.7531\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.8149 - val_loss: 0.7518\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8133 - val_loss: 0.7505\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8118 - val_loss: 0.7491\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 193ms/step - loss: 0.8102 - val_loss: 0.7477\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8086 - val_loss: 0.7463\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8069 - val_loss: 0.7448\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8053 - val_loss: 0.7433\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 0.8035 - val_loss: 0.7418\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.8018 - val_loss: 0.7402\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7999 - val_loss: 0.7385\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7980 - val_loss: 0.7368\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7961 - val_loss: 0.7351\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.7941 - val_loss: 0.7332\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7920 - val_loss: 0.7313\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7898 - val_loss: 0.7293\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7875 - val_loss: 0.7272\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7851 - val_loss: 0.7250\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7826 - val_loss: 0.7227\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7798 - val_loss: 0.7202\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.7769 - val_loss: 0.7177\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7736 - val_loss: 0.7150\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7701 - val_loss: 0.7123\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.7660 - val_loss: 0.7101\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7615 - val_loss: 0.7082\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.7563 - val_loss: 0.7078\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7505 - val_loss: 0.7144\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.7446 - val_loss: 0.7486\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7395 - val_loss: 0.8060\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7367 - val_loss: 0.8444\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7335 - val_loss: 0.8419\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.7292 - val_loss: 0.8221\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7251 - val_loss: 0.8054\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 194ms/step - loss: 0.7211 - val_loss: 0.8013\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7169 - val_loss: 0.8089\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.7126 - val_loss: 0.8216\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7082 - val_loss: 0.8375\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7035 - val_loss: 0.8562\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6987 - val_loss: 0.8791\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6936 - val_loss: 0.9061\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.6885 - val_loss: 0.9309\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6835 - val_loss: 0.9342\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6783 - val_loss: 0.9178\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6734 - val_loss: 0.9062\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6686 - val_loss: 0.9131\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.6639 - val_loss: 0.9277\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.6593 - val_loss: 0.9228\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6548 - val_loss: 0.8990\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6503 - val_loss: 0.8809\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.6459 - val_loss: 0.8698\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.6414 - val_loss: 0.8593\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6370 - val_loss: 0.8503\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6326 - val_loss: 0.8358\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6284 - val_loss: 0.8167\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6243 - val_loss: 0.8016\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6204 - val_loss: 0.7904\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6166 - val_loss: 0.7797\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6130 - val_loss: 0.7699\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.6094 - val_loss: 0.7627\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.6058 - val_loss: 0.7573\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6023 - val_loss: 0.7513\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.5988 - val_loss: 0.7473\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.5952 - val_loss: 0.7467\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.5917 - val_loss: 0.7448\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.5882 - val_loss: 0.7388\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.5847 - val_loss: 0.7335\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.5812 - val_loss: 0.7298\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5776 - val_loss: 0.7253\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.5740 - val_loss: 0.7206\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.5702 - val_loss: 0.7150\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5662 - val_loss: 0.7088\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.5618 - val_loss: 0.7036\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.5569 - val_loss: 0.6993\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5509 - val_loss: 0.6957\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_78\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_79 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_78 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 247ms/step - loss: 0.8490 - val_loss: 0.7792\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8477 - val_loss: 0.7782\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8465 - val_loss: 0.7773\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8454 - val_loss: 0.7763\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.8442 - val_loss: 0.7754\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8430 - val_loss: 0.7744\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8418 - val_loss: 0.7734\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.8406 - val_loss: 0.7725\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8394 - val_loss: 0.7715\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8383 - val_loss: 0.7705\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.8371 - val_loss: 0.7696\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.8359 - val_loss: 0.7686\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.8347 - val_loss: 0.7676\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8335 - val_loss: 0.7666\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8323 - val_loss: 0.7656\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.8311 - val_loss: 0.7646\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8298 - val_loss: 0.7636\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.8286 - val_loss: 0.7625\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.8273 - val_loss: 0.7615\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8260 - val_loss: 0.7604\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8247 - val_loss: 0.7593\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.8234 - val_loss: 0.7582\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 0.8220 - val_loss: 0.7571\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.8206 - val_loss: 0.7559\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8192 - val_loss: 0.7547\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.8178 - val_loss: 0.7535\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8164 - val_loss: 0.7523\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.8149 - val_loss: 0.7511\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.8134 - val_loss: 0.7498\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8118 - val_loss: 0.7485\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8102 - val_loss: 0.7472\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.8086 - val_loss: 0.7458\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.8069 - val_loss: 0.7444\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.8052 - val_loss: 0.7430\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.8035 - val_loss: 0.7415\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.8017 - val_loss: 0.7399\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7998 - val_loss: 0.7383\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7979 - val_loss: 0.7367\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7960 - val_loss: 0.7351\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7939 - val_loss: 0.7333\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7918 - val_loss: 0.7315\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.7896 - val_loss: 0.7297\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7874 - val_loss: 0.7278\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7850 - val_loss: 0.7257\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.7826 - val_loss: 0.7237\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7800 - val_loss: 0.7215\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7773 - val_loss: 0.7193\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7745 - val_loss: 0.7169\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.7715 - val_loss: 0.7145\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7683 - val_loss: 0.7118\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7650 - val_loss: 0.7091\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7613 - val_loss: 0.7062\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.7574 - val_loss: 0.7032\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7531 - val_loss: 0.7003\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.7484 - val_loss: 0.6977\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.7431 - val_loss: 0.6960\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7371 - val_loss: 0.6957\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7302 - val_loss: 0.6995\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7223 - val_loss: 0.7134\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7141 - val_loss: 0.7613\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.7085 - val_loss: 0.8959\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7086 - val_loss: 0.9336\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.7031 - val_loss: 0.8292\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6990 - val_loss: 0.7766\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6960 - val_loss: 0.7606\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6926 - val_loss: 0.7631\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6890 - val_loss: 0.7743\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6853 - val_loss: 0.7832\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6813 - val_loss: 0.7795\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6768 - val_loss: 0.7678\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.6716 - val_loss: 0.7570\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.6656 - val_loss: 0.7501\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.6597 - val_loss: 0.7471\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.6573 - val_loss: 0.7463\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6536 - val_loss: 0.7462\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6502 - val_loss: 0.7445\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6478 - val_loss: 0.7406\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6452 - val_loss: 0.7361\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6421 - val_loss: 0.7320\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.6388 - val_loss: 0.7286\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.6355 - val_loss: 0.7255\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6319 - val_loss: 0.7227\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.6281 - val_loss: 0.7195\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6240 - val_loss: 0.7160\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6190 - val_loss: 0.7126\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6118 - val_loss: 0.7094\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.6055 - val_loss: 0.7066\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.6010 - val_loss: 0.7050\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.5978 - val_loss: 0.7031\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.5906 - val_loss: 0.7010\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5878 - val_loss: 0.6992\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.5870 - val_loss: 0.6972\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.5814 - val_loss: 0.6943\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.5820 - val_loss: 0.6921\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.5766 - val_loss: 0.6908\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.5736 - val_loss: 0.6884\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5710 - val_loss: 0.6860\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.5665 - val_loss: 0.6845\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.5645 - val_loss: 0.6829\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.5616 - val_loss: 0.6813\n",
            "(2138, 365, 1)\n",
            "(2138, 1)\n",
            "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_79\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_80 (InputLayer)       [(None, 50, 1)]           0         \n",
            "                                                                 \n",
            " lstm_79 (LSTM)              (None, 25)                2700      \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 7)                 182       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,882\n",
            "Trainable params: 2,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 244ms/step - loss: 0.8278 - val_loss: 0.7627\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.8265 - val_loss: 0.7617\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8253 - val_loss: 0.7606\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8241 - val_loss: 0.7596\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.8229 - val_loss: 0.7585\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.8217 - val_loss: 0.7575\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.8205 - val_loss: 0.7564\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8194 - val_loss: 0.7554\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8182 - val_loss: 0.7544\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8169 - val_loss: 0.7533\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.8157 - val_loss: 0.7522\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.8144 - val_loss: 0.7511\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8131 - val_loss: 0.7499\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8117 - val_loss: 0.7487\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.8102 - val_loss: 0.7475\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.8088 - val_loss: 0.7462\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.8073 - val_loss: 0.7449\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.8058 - val_loss: 0.7437\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.8044 - val_loss: 0.7424\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.8029 - val_loss: 0.7411\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.8014 - val_loss: 0.7398\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.7999 - val_loss: 0.7385\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7984 - val_loss: 0.7371\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7969 - val_loss: 0.7358\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7953 - val_loss: 0.7345\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.7937 - val_loss: 0.7331\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7921 - val_loss: 0.7317\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7905 - val_loss: 0.7303\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.7888 - val_loss: 0.7288\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7871 - val_loss: 0.7274\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7854 - val_loss: 0.7259\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7836 - val_loss: 0.7244\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.7817 - val_loss: 0.7228\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.7799 - val_loss: 0.7212\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7780 - val_loss: 0.7196\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7760 - val_loss: 0.7180\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.7740 - val_loss: 0.7163\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7719 - val_loss: 0.7146\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7697 - val_loss: 0.7129\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.7675 - val_loss: 0.7111\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7652 - val_loss: 0.7093\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7628 - val_loss: 0.7074\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.7603 - val_loss: 0.7054\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.7577 - val_loss: 0.7034\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.7550 - val_loss: 0.7014\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.7522 - val_loss: 0.6992\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.7492 - val_loss: 0.6970\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.7460 - val_loss: 0.6947\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.7426 - val_loss: 0.6923\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.7390 - val_loss: 0.6897\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.7350 - val_loss: 0.6870\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.7306 - val_loss: 0.6842\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.7256 - val_loss: 0.6812\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.7199 - val_loss: 0.6780\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.7130 - val_loss: 0.6746\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.7045 - val_loss: 0.6709\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 195ms/step - loss: 0.6933 - val_loss: 0.6669\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6773 - val_loss: 0.6625\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.6674 - val_loss: 0.6591\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.6582 - val_loss: 0.6587\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6619 - val_loss: 0.6575\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 195ms/step - loss: 0.6607 - val_loss: 0.6557\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6564 - val_loss: 0.6536\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.6491 - val_loss: 0.6512\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.6418 - val_loss: 0.6487\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.6417 - val_loss: 0.6470\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.6365 - val_loss: 0.6459\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.6364 - val_loss: 0.6443\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.6322 - val_loss: 0.6421\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.6281 - val_loss: 0.6399\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.6250 - val_loss: 0.6382\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 0.6222 - val_loss: 0.6367\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.6200 - val_loss: 0.6347\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.6169 - val_loss: 0.6326\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 0.6140 - val_loss: 0.6307\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.6115 - val_loss: 0.6289\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.6089 - val_loss: 0.6267\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.6063 - val_loss: 0.6246\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.6035 - val_loss: 0.6226\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.6007 - val_loss: 0.6201\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.5978 - val_loss: 0.6178\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.5948 - val_loss: 0.6153\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.5918 - val_loss: 0.6125\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.5883 - val_loss: 0.6096\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5849 - val_loss: 0.6063\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.5813 - val_loss: 0.6029\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5775 - val_loss: 0.5993\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.5736 - val_loss: 0.5954\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5695 - val_loss: 0.5912\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.5650 - val_loss: 0.5867\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.5600 - val_loss: 0.5820\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.5549 - val_loss: 0.5770\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5491 - val_loss: 0.5729\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.5426 - val_loss: 0.5717\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.5352 - val_loss: 0.5771\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.5267 - val_loss: 0.6068\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.5171 - val_loss: 0.7452\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.5083 - val_loss: 1.2349\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.5049 - val_loss: 1.7531\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.5049 - val_loss: 1.7108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "bKFH3_vOsnP7",
        "outputId": "5aa0f918-7dad-464f-d007-9cae0fd58835"
      },
      "source": [
        "# After model has trained we can now check the results and plot some curves\n",
        "\n",
        "# Extract the training loss and validation loss\n",
        "loss = history.history.get('loss')\n",
        "val_loss = history.history.get('val_loss')\n",
        "\n",
        "# Get the number of epochs that was run before cutting off\n",
        "n_epochs = range(len(loss))\n",
        "\n",
        "# Plot the training loss and val loss\n",
        "plt.figure(figsize=(9, 7))\n",
        "plt.plot(n_epochs, loss, 'r', label='Training loss', color='blue')\n",
        "if val_loss is not None:\n",
        "    plt.plot(n_epochs, val_loss, 'r', label='Validation loss', color='red')\n",
        "plt.legend(loc=0)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()\n",
        "\n",
        "# Forecasts against the actual values\n",
        "forecast = model_pair1.predict(Xval)\n",
        "\n",
        "# Plot the forecasts\n",
        "yhat = forecast[1:751,]*train_std +train_mean\n",
        "y = Yval*train_std +train_mean\n",
        "\n",
        "plt.plot(yhat,color='red')\n",
        "plt.plot(y,color='blue')\n",
        "plt.show()\n",
        "\n",
        "# Test period \n",
        "test_forecast_1= model_pair1.predict(Xtest)\n",
        "test_forecast_1 = test_forecast_1*test_std+test_mean\n",
        "plot(test_forecast_1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x504 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-d3b3b87a824c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Test period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtest_forecast_1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_pair1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mtest_forecast_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_forecast_1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest_std\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_forecast_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Xtest' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5rP2Jrh_W4s",
        "outputId": "2c63fd36-7f0d-4a2d-c9fe-6f821d11f8e0"
      },
      "source": [
        "print(train_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8359.024690229215\n"
          ]
        }
      ]
    }
  ]
}